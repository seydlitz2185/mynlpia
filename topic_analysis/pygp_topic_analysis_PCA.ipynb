{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='your module name')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载自制中文数据集、分词、去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/f0/6j6j3w814n53skbt2s4d8p5m0000gn/T/jieba.cache\n",
      "Loading model cost 0.503 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "/var/folders/f0/6j6j3w814n53skbt2s4d8p5m0000gn/T/ipykernel_21518/2493417845.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text\"].iloc[i] = ' '.join(words)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('smalldata_washed.csv')\n",
    "rumor = data['rumor'].to_list()\n",
    "reverse = data['reverse'].to_list()\n",
    "rumor_class = len(rumor)*[1]\n",
    "reverse_class = len(reverse)*[0]\n",
    "data = rumor + reverse\n",
    "data_class = rumor_class + reverse_class\n",
    "#后续添加数据要放在raw目录下，使用.xlsx格式将后续标注的数据加入data\n",
    "raw_data_list = os.listdir('raw')\n",
    "data_list = []\n",
    "good_name = re.compile(r'^(?!(\\~\\$)).*(.xlsx)')\n",
    "for i in raw_data_list:\n",
    "    if good_name.match(i):\n",
    "    #    data_list.append(i)\n",
    "        temp = pd.read_excel('raw/'+i)\n",
    "        temp.fillna('',inplace=True)\n",
    "        temp_rumor = [x.strip() for x in  temp['punc_rumor'].to_list()  if x.strip()!='']\n",
    "        temp_reverse = [x.strip() for x in  temp['punc_truth'].to_list()  if x.strip()!='']\n",
    "        temp_rumor_class = len(temp_rumor)*[1]\n",
    "        temp_reverse_class = len(temp_reverse)*[0]\n",
    "        temp_data = temp_rumor + temp_reverse\n",
    "        temp_data_class = temp_rumor_class + temp_reverse_class\n",
    "        for i in range( len(temp_data)):\n",
    "            temp_data[i]=re.sub(r'[\\,\\'\\ ]|(\\n)','',temp_data[i])\n",
    "    data = data + temp_data\n",
    "    data_class = data_class + temp_data_class\n",
    "with open('data.txt','w') as f:\n",
    "    for i in range(len(data)):\n",
    "        f.write(data[i]+'\\t'+str(data_class[i])+'\\n')\n",
    "        data_list =list( zip(data, data_class))\n",
    "random.shuffle(data_list)\n",
    "data, data_class = zip(*data_list)\n",
    "index = ['rumor{}{}'.format(i, '!' * j) for (i, j) in zip(range(len(data)), data_class)]\n",
    "df = pd .DataFrame(data=zip(data_class,data), columns=[\"rumor\",\"text\"], index=index)\n",
    "\n",
    "# 去除停用词\n",
    "with open ('hit_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "\n",
    "# jieba分词\n",
    "import jieba\n",
    "for i in range(len(df)):\n",
    "    words = jieba.cut(df[\"text\"].iloc[i],cut_all=False)\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    df[\"text\"].iloc[i] = ' '.join(words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenyu/opt/anaconda3/envs/d2l/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import casual_tokenize\n",
    "tfidf = TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "tfidf_docs = tfidf.fit_transform(raw_documents=df.text).toarray()\n",
    "len(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "913"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_docs = pd.DataFrame(tfidf_docs)\n",
    "#通过减去每个文档（词袋向量）的平均值来中心化文档\n",
    "tfidf_docs = tfidf_docs - tfidf_docs.mean()\n",
    "tfidf_docs.shape\n",
    "df.rumor.sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于PCA的短消息语义分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "k=min(len(tfidf.vocabulary_),len(df))\n",
    "k=300\n",
    "pca = PCA(n_components=k)\n",
    "pca_docs = pca.fit_transform(tfidf_docs)\n",
    "base = sum(pca.singular_values_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = pca.singular_values_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(len(nums)):\\n    if(sum(nums[:i+1])/base>0.5):\\n        k=i\\n        break\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for i in range(len(nums)):\n",
    "    if(sum(nums[:i+1])/base>0.5):\n",
    "        k=i\n",
    "        break\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic290</th>\n",
       "      <th>topic291</th>\n",
       "      <th>topic292</th>\n",
       "      <th>topic293</th>\n",
       "      <th>topic294</th>\n",
       "      <th>topic295</th>\n",
       "      <th>topic296</th>\n",
       "      <th>topic297</th>\n",
       "      <th>topic298</th>\n",
       "      <th>topic299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0!</th>\n",
       "      <td>0.062</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1!</th>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.063</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2</th>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3!</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.073</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4</th>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor5!</th>\n",
       "      <td>0.151</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  \\\n",
       "rumor0!   0.062  -0.020   0.056  -0.095  -0.036   0.083   0.044   0.023   \n",
       "rumor1!   0.029  -0.047  -0.022   0.017  -0.026  -0.063  -0.011  -0.009   \n",
       "rumor2    0.055  -0.014   0.019  -0.000   0.018   0.075  -0.050   0.020   \n",
       "rumor3!   0.003   0.073  -0.045   0.078   0.051  -0.004  -0.051  -0.105   \n",
       "rumor4    0.027  -0.029  -0.026   0.018  -0.032  -0.052   0.001   0.001   \n",
       "rumor5!   0.151   0.020   0.060   0.016  -0.050   0.020   0.028   0.008   \n",
       "\n",
       "         topic8  topic9  ...  topic290  topic291  topic292  topic293  \\\n",
       "rumor0!  -0.042   0.009  ...     0.010     0.010    -0.005    -0.024   \n",
       "rumor1!  -0.017   0.001  ...    -0.025     0.053     0.046     0.021   \n",
       "rumor2    0.008  -0.029  ...    -0.010    -0.018     0.019    -0.013   \n",
       "rumor3!  -0.008   0.104  ...     0.032    -0.020    -0.017    -0.011   \n",
       "rumor4   -0.031  -0.004  ...     0.027    -0.000     0.002    -0.016   \n",
       "rumor5!  -0.019   0.010  ...     0.021    -0.039    -0.009    -0.008   \n",
       "\n",
       "         topic294  topic295  topic296  topic297  topic298  topic299  \n",
       "rumor0!     0.033     0.069     0.016     0.002     0.032     0.019  \n",
       "rumor1!     0.016    -0.024     0.009    -0.018    -0.016    -0.024  \n",
       "rumor2      0.008     0.008     0.054     0.014    -0.007     0.025  \n",
       "rumor3!    -0.018     0.004     0.014    -0.016    -0.006     0.033  \n",
       "rumor4      0.006     0.009    -0.021     0.021    -0.054     0.025  \n",
       "rumor5!    -0.011    -0.028     0.005    -0.015    -0.000    -0.026  \n",
       "\n",
       "[6 rows x 300 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=k)\n",
    "pca_docs = pca.fit_transform(tfidf_docs)\n",
    "pca_topic_vectors = pca.transform(tfidf_docs)\n",
    "columns = ['topic{}'.format(i) for i in range(pca_docs.shape[1])]\n",
    "pca_topic_vectors = pd.DataFrame(pca_topic_vectors, columns=columns, index=index)\n",
    "pca_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.vocabulary_\n",
    "#根据词项的频率对词汇表进行排序\n",
    "#当对某个不按照最左边元素排序的序列解压并在排序后重新压缩时，可以使用zip(*sorted(zip(...)))\n",
    "column_nums , terms = zip(*sorted(zip(tfidf.vocabulary_.values(), tfidf.vocabulary_.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%</th>\n",
       "      <th>.</th>\n",
       "      <th>0</th>\n",
       "      <th>0t</th>\n",
       "      <th>...</th>\n",
       "      <th>鼻炎</th>\n",
       "      <th>鼻翼</th>\n",
       "      <th>龋齿</th>\n",
       "      <th>龙葵</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic1</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic2</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic3</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 9200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            %      .    0     0t  ...     鼻炎     鼻翼     龋齿     龙葵\n",
       "topic0  0.001 -0.001  0.0 -0.000  ... -0.000  0.000  0.001 -0.001\n",
       "topic1 -0.001  0.000 -0.0 -0.001  ... -0.002 -0.000 -0.001 -0.002\n",
       "topic2 -0.001  0.001 -0.0 -0.001  ... -0.002 -0.001 -0.001  0.000\n",
       "topic3  0.000  0.004  0.0  0.001  ... -0.002  0.001  0.001 -0.002\n",
       "\n",
       "[4 rows x 9200 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = pd.DataFrame(pca.components_, columns=terms,\n",
    "                       index = ['topic{}'.format(i) for i in range(pca.components_.shape[0])])\n",
    "pd.options.display.max_columns = 8\n",
    "weights.head(4).round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于截断的SVD的短消息语义分析（recommend）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=k,n_iter=100)\n",
    "svd_topic_vectors = svd.fit_transform(tfidf_docs.values)\n",
    "svd_topic_vectors = pd.DataFrame(svd_topic_vectors, columns=columns, index=index)\n",
    "svd_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(svd_topic_vectors,df.rumor,test_size=0.2 ,random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "# 进行过采样\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"过采样前训练集中类别0的数量：\", sum(y_train==0))\n",
    "print(\"过采样前训练集中类别1的数量：\", sum(y_train==1))\n",
    "\n",
    "print(\"过采样后训练集中类别0的数量：\", sum(y_train_res==0))\n",
    "print(\"过采样后训练集中类别1的数量：\", sum(y_train_res==1))\n",
    "lda = LDA(n_components=1)\n",
    "lda = lda.fit(X_train_res, y_train_res)\n",
    "df['LSA16_rumor'] = lda.predict(svd_topic_vectors)\n",
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过采样前训练集中类别0的数量： 1559\n",
      "过采样前训练集中类别1的数量： 433\n",
      "过采样后训练集中类别0的数量： 1559\n",
      "过采样后训练集中类别1的数量： 1559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.801"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(svd_topic_vectors,df.rumor,test_size=0.2 ,random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "# 进行过采样\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"过采样前训练集中类别0的数量：\", sum(y_train==0))\n",
    "print(\"过采样前训练集中类别1的数量：\", sum(y_train==1))\n",
    "\n",
    "print(\"过采样后训练集中类别0的数量：\", sum(y_train_res==0))\n",
    "print(\"过采样后训练集中类别1的数量：\", sum(y_train_res==1))\n",
    "lda = LDA(n_components=1)\n",
    "lda = lda.fit(X_train_res, y_train_res)\n",
    "df['LSA16_rumor'] = lda.predict(svd_topic_vectors)\n",
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rumor0!</th>\n",
       "      <th>rumor1</th>\n",
       "      <th>rumor2!</th>\n",
       "      <th>rumor3</th>\n",
       "      <th>...</th>\n",
       "      <th>rumor6</th>\n",
       "      <th>rumor7!</th>\n",
       "      <th>rumor8!</th>\n",
       "      <th>rumor9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0!</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2!</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor5</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor6</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor7!</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor8!</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rumor0!  rumor1  rumor2!  rumor3  ...  rumor6  rumor7!  rumor8!  \\\n",
       "rumor0!      1.0    -0.1      0.0    -0.0  ...    -0.0     -0.0      0.0   \n",
       "rumor1      -0.1     1.0     -0.1    -0.1  ...     0.1     -0.0     -0.1   \n",
       "rumor2!      0.0    -0.1      1.0     0.0  ...     0.0     -0.0      0.0   \n",
       "rumor3      -0.0    -0.1      0.0     1.0  ...    -0.1      0.4     -0.0   \n",
       "rumor4      -0.0    -0.1      0.3    -0.1  ...    -0.1      0.1      0.0   \n",
       "rumor5      -0.0     0.3      0.1    -0.1  ...    -0.1     -0.0     -0.0   \n",
       "rumor6      -0.0     0.1      0.0    -0.1  ...     1.0      0.2     -0.0   \n",
       "rumor7!     -0.0    -0.0     -0.0     0.4  ...     0.2      1.0      0.0   \n",
       "rumor8!      0.0    -0.1      0.0    -0.0  ...    -0.0      0.0      1.0   \n",
       "rumor9       0.0    -0.1     -0.1     0.0  ...    -0.0      0.0     -0.0   \n",
       "\n",
       "         rumor9  \n",
       "rumor0!     0.0  \n",
       "rumor1     -0.1  \n",
       "rumor2!    -0.1  \n",
       "rumor3      0.0  \n",
       "rumor4     -0.1  \n",
       "rumor5     -0.0  \n",
       "rumor6     -0.0  \n",
       "rumor7!     0.0  \n",
       "rumor8!    -0.0  \n",
       "rumor9      1.0  \n",
       "\n",
       "[10 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "svd_topic_vectors = (svd_topic_vectors.T / np.linalg.norm(svd_topic_vectors,axis=1)).T\n",
    "svd_topic_vectors.iloc[:10].dot(svd_topic_vectors.iloc[:10].T).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lda' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m cross_val_score\n\u001b[0;32m----> 2\u001b[0m scores \u001b[39m=\u001b[39m cross_val_score(lda, svd_topic_vectors, df\u001b[39m.\u001b[39mrumor, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mrumor Accuracy: \u001b[39m\u001b[39m%0.4f\u001b[39;00m\u001b[39m (+/- \u001b[39m\u001b[39m%0.4f\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (scores\u001b[39m.\u001b[39mmean(), scores\u001b[39m.\u001b[39mstd() \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lda' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(lda, svd_topic_vectors, df.rumor, cv=5)\n",
    "print(\"rumor Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro: p 0.7554878323378912, r 0.8471424815354829, f1 0.7749943201355496\n",
      "micro: p 0.8164658634538152, r 0.8164658634538152, f1 0.8164658634538152\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_recall_fscore_support\n",
    "y_true = df.rumor\n",
    "y_pred = df.LSA16_rumor\n",
    "p_macro, r_macro, f_macro, support_macro \\\n",
    "    = precision_recall_fscore_support(y_true=y_true, y_pred=y_pred, labels=[0,1], average='macro')\n",
    "\n",
    "p_micro, r_micro, f_micro, support_micro\\\n",
    "    = precision_recall_fscore_support(y_true=y_true, y_pred=y_pred, labels=[0,1], average='micro')\n",
    "\n",
    "print('macro: p {}, r {}, f1 {}'.format(p_macro, r_macro, f_macro))\n",
    "\n",
    "print('micro: p {}, r {}, f1 {}'.format(p_micro, r_micro, f_micro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenyu/opt/anaconda3/envs/d2l/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   non-rumor     0.9569    0.7854    0.8627       396\n",
      "       rumor     0.5087    0.8627    0.6400       102\n",
      "\n",
      "    accuracy                         0.8012       498\n",
      "   macro avg     0.7328    0.8240    0.7513       498\n",
      "weighted avg     0.8651    0.8012    0.8171       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "y_true = df.loc[y_test.index].rumor\n",
    "y_pred = df.loc[y_test.index].LSA16_rumor\n",
    "loss_total = 0\n",
    "acc = metrics.accuracy_score(y_true, y_pred)\n",
    "report = metrics.classification_report(y_true, y_pred, target_names=[\"non-rumor\",\"rumor\"], digits=4)\n",
    "confusion = metrics.confusion_matrix(y_true, y_pred)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6d40a5097db4c11f3975da84c5456511726d6f156896da7e31bb0c17b283947"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
