{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载自制中文数据集、分词、去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f0/6j6j3w814n53skbt2s4d8p5m0000gn/T/ipykernel_12357/1622170239.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text\"].iloc[i] = ' '.join(words)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('smalldata_washed.csv')\n",
    "rumor = data['rumor'].to_list()\n",
    "reverse = data['reverse'].to_list()\n",
    "rumor_class = len(rumor)*[1]\n",
    "reverse_class = len(reverse)*[0]\n",
    "data = rumor + reverse\n",
    "data_class = rumor_class + reverse_class\n",
    "#后续添加数据要放在raw目录下，使用.xlsx格式将后续标注的数据加入data\n",
    "raw_data_list = os.listdir('raw')\n",
    "data_list = []\n",
    "good_name = re.compile(r'^(?!(\\~\\$)).*(.xlsx)')\n",
    "for i in raw_data_list:\n",
    "    if good_name.match(i):\n",
    "    #    data_list.append(i)\n",
    "        temp = pd.read_excel('raw/'+i)\n",
    "        temp.fillna('',inplace=True)\n",
    "        temp_rumor = [x.strip() for x in  temp['谣言'].to_list()  if x.strip()!='']\n",
    "        temp_reverse = [x.strip() for x in  temp['真相'].to_list()  if x.strip()!='']\n",
    "        temp_rumor_class = len(temp_rumor)*[1]\n",
    "        temp_reverse_class = len(temp_reverse)*[0]\n",
    "        temp_data = temp_rumor + temp_reverse\n",
    "        temp_data_class = temp_rumor_class + temp_reverse_class\n",
    "        for i in range( len(temp_data)):\n",
    "            temp_data[i]=re.sub(r'[\\,\\'\\ ]|(\\n)','',temp_data[i])\n",
    "    data = data + temp_data\n",
    "    data_class = data_class + temp_data_class\n",
    "with open('data.txt','w') as f:\n",
    "    for i in range(len(data)):\n",
    "        f.write(data[i]+'\\t'+str(data_class[i])+'\\n')\n",
    "        data_list =list( zip(data, data_class))\n",
    "random.shuffle(data_list)\n",
    "data, data_class = zip(*data_list)\n",
    "index = ['rumor{}{}'.format(i, '!' * j) for (i, j) in zip(range(len(data)), data_class)]\n",
    "df = pd .DataFrame(data=zip(data_class,data), columns=[\"rumor\",\"text\"], index=index)\n",
    "\n",
    "# 去除停用词\n",
    "with open ('hit_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "\n",
    "# jieba分词\n",
    "import jieba\n",
    "for i in range(len(df)):\n",
    "    words = jieba.cut(df[\"text\"].iloc[i],cut_all=False)\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    df[\"text\"].iloc[i] = ' '.join(words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenyu/opt/anaconda3/envs/nlpiaenv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4021"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import casual_tokenize\n",
    "tfidf = TfidfVectorizer(tokenizer=casual_tokenize)\n",
    "tfidf_docs = tfidf.fit_transform(raw_documents=df.text).toarray()\n",
    "len(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_docs = pd.DataFrame(tfidf_docs)\n",
    "#通过减去每个文档（词袋向量）的平均值来中心化文档\n",
    "tfidf_docs = tfidf_docs - tfidf_docs.mean()\n",
    "tfidf_docs.shape\n",
    "df.rumor.sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于PCA的短消息语义分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>...</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0</th>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1</th>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2</th>\n",
       "      <td>0.032</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3!</th>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.021</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4!</th>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.104</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor5</th>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic0  topic1  topic2  topic3  ...  topic12  topic13  topic14  \\\n",
       "rumor0   -0.046   0.056  -0.012  -0.014  ...   -0.103    0.005    0.042   \n",
       "rumor1   -0.059  -0.039   0.028   0.001  ...   -0.019   -0.008    0.002   \n",
       "rumor2    0.032   0.030  -0.042   0.009  ...   -0.020   -0.046    0.022   \n",
       "rumor3!  -0.022   0.108  -0.050   0.021  ...   -0.090    0.016    0.064   \n",
       "rumor4!  -0.035  -0.078  -0.025   0.079  ...   -0.079    0.104   -0.048   \n",
       "rumor5    0.166  -0.035   0.036  -0.107  ...   -0.019   -0.010   -0.039   \n",
       "\n",
       "         topic15  \n",
       "rumor0     0.109  \n",
       "rumor1    -0.041  \n",
       "rumor2    -0.065  \n",
       "rumor3!   -0.094  \n",
       "rumor4!    0.185  \n",
       "rumor5     0.015  \n",
       "\n",
       "[6 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=16)\n",
    "pca_docs = pca.fit_transform(tfidf_docs)\n",
    "pca_topic_vectors = pca.transform(tfidf_docs)\n",
    "columns = ['topic{}'.format(i) for i in range(pca_docs.shape[1])]\n",
    "pca_topic_vectors = pd.DataFrame(pca_topic_vectors, columns=columns, index=index)\n",
    "pca_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.vocabulary_\n",
    "#根据词项的频率对词汇表进行排序\n",
    "#当对某个不按照最左边元素排序的序列解压并在排序后重新压缩时，可以使用zip(*sorted(zip(...)))\n",
    "column_nums , terms = zip(*sorted(zip(tfidf.vocabulary_.values(), tfidf.vocabulary_.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%</th>\n",
       "      <th>0</th>\n",
       "      <th>0t</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>鼓励</th>\n",
       "      <th>鼻出血</th>\n",
       "      <th>鼻翼</th>\n",
       "      <th>龋齿</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>topic0</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic1</th>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic2</th>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topic3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 4021 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            %      0     0t      1  ...     鼓励    鼻出血     鼻翼     龋齿\n",
       "topic0 -0.001 -0.001 -0.004 -0.003  ... -0.001 -0.004 -0.002 -0.003\n",
       "topic1 -0.003 -0.000 -0.002 -0.011  ... -0.002 -0.008 -0.002 -0.004\n",
       "topic2 -0.001  0.000  0.001 -0.009  ... -0.001 -0.001  0.000 -0.001\n",
       "topic3  0.001 -0.000  0.003  0.007  ... -0.003 -0.000  0.001  0.002\n",
       "\n",
       "[4 rows x 4021 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = pd.DataFrame(pca.components_, columns=terms,\n",
    "                       index = ['topic{}'.format(i) for i in range(pca.components_.shape[0])])\n",
    "pd.options.display.max_columns = 8\n",
    "weights.head(4).round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于截断的SVD的短消息语义分析（recommend）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>...</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0</th>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1</th>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2</th>\n",
       "      <td>0.031</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3!</th>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4!</th>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor5</th>\n",
       "      <td>0.166</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic0  topic1  topic2  topic3  ...  topic12  topic13  topic14  \\\n",
       "rumor0   -0.046   0.056  -0.011  -0.015  ...   -0.086    0.060    0.043   \n",
       "rumor1   -0.060  -0.038   0.029   0.002  ...   -0.019   -0.012   -0.031   \n",
       "rumor2    0.031   0.030  -0.042   0.009  ...   -0.025   -0.047   -0.055   \n",
       "rumor3!  -0.022   0.108  -0.052   0.020  ...   -0.023    0.075   -0.107   \n",
       "rumor4!  -0.035  -0.078  -0.026   0.077  ...   -0.016    0.096    0.140   \n",
       "rumor5    0.166  -0.035   0.036  -0.106  ...   -0.035    0.004    0.014   \n",
       "\n",
       "         topic15  \n",
       "rumor0    -0.087  \n",
       "rumor1     0.026  \n",
       "rumor2    -0.026  \n",
       "rumor3!   -0.037  \n",
       "rumor4!   -0.031  \n",
       "rumor5     0.040  \n",
       "\n",
       "[6 rows x 16 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=16,n_iter=100)\n",
    "svd_topic_vectors = svd.fit_transform(tfidf_docs.values)\n",
    "svd_topic_vectors = pd.DataFrame(svd_topic_vectors, columns=columns, index=index)\n",
    "svd_topic_vectors.round(3).head(6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 基于LSA的垃圾短消息分类的效果(PCA/SVD+LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过采样前训练集中类别0的数量： 234\n",
      "过采样前训练集中类别1的数量： 165\n",
      "过采样后训练集中类别0的数量： 234\n",
      "过采样后训练集中类别1的数量： 234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.667"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(svd_topic_vectors,df.rumor,test_size=0.5,random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "# 进行过采样\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"过采样前训练集中类别0的数量：\", sum(y_train==0))\n",
    "print(\"过采样前训练集中类别1的数量：\", sum(y_train==1))\n",
    "\n",
    "print(\"过采样后训练集中类别0的数量：\", sum(y_train_res==0))\n",
    "print(\"过采样后训练集中类别1的数量：\", sum(y_train_res==1))\n",
    "lda = LDA(n_components=1)\n",
    "lda = lda.fit(X_train_res, y_train_res)\n",
    "df['LSA16_rumor'] = lda.predict(svd_topic_vectors)\n",
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rumor0</th>\n",
       "      <th>rumor1</th>\n",
       "      <th>rumor2</th>\n",
       "      <th>rumor3!</th>\n",
       "      <th>...</th>\n",
       "      <th>rumor6!</th>\n",
       "      <th>rumor7!</th>\n",
       "      <th>rumor8</th>\n",
       "      <th>rumor9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3!</th>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4!</th>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor5</th>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor6!</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor7!</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor9</th>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rumor0  rumor1  rumor2  rumor3!  ...  rumor6!  rumor7!  rumor8  \\\n",
       "rumor0      1.0     0.2     0.2      0.2  ...     -0.1      0.3     0.1   \n",
       "rumor1      0.2     1.0     0.2     -0.1  ...     -0.5      0.4     0.2   \n",
       "rumor2      0.2     0.2     1.0      0.4  ...      0.1      0.7     0.3   \n",
       "rumor3!     0.2    -0.1     0.4      1.0  ...      0.3     -0.3     0.2   \n",
       "rumor4!     0.4    -0.0    -0.2     -0.0  ...     -0.3     -0.1     0.1   \n",
       "rumor5     -0.2    -0.4    -0.2     -0.2  ...      0.6     -0.2    -0.2   \n",
       "rumor6!    -0.1    -0.5     0.1      0.3  ...      1.0     -0.2    -0.1   \n",
       "rumor7!     0.3     0.4     0.7     -0.3  ...     -0.2      1.0     0.1   \n",
       "rumor8      0.1     0.2     0.3      0.2  ...     -0.1      0.1     1.0   \n",
       "rumor9     -0.6     0.4    -0.1     -0.0  ...     -0.2     -0.1    -0.1   \n",
       "\n",
       "         rumor9  \n",
       "rumor0     -0.6  \n",
       "rumor1      0.4  \n",
       "rumor2     -0.1  \n",
       "rumor3!    -0.0  \n",
       "rumor4!    -0.2  \n",
       "rumor5     -0.2  \n",
       "rumor6!    -0.2  \n",
       "rumor7!    -0.1  \n",
       "rumor8     -0.1  \n",
       "rumor9      1.0  \n",
       "\n",
       "[10 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "svd_topic_vectors = (svd_topic_vectors.T / np.linalg.norm(svd_topic_vectors,axis=1)).T\n",
    "svd_topic_vectors.iloc[:10].dot(svd_topic_vectors.iloc[:10].T).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.70 (+/- 0.03)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(lda, svd_topic_vectors, df.rumor, cv=5)\n",
    "\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpiaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
