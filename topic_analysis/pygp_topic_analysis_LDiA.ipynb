{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='your module name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/f0/6j6j3w814n53skbt2s4d8p5m0000gn/T/jieba.cache\n",
      "Loading model cost 0.310 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "/var/folders/f0/6j6j3w814n53skbt2s4d8p5m0000gn/T/ipykernel_46245/2493417845.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text\"].iloc[i] = ' '.join(words)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('smalldata_washed.csv')\n",
    "rumor = data['rumor'].to_list()\n",
    "reverse = data['reverse'].to_list()\n",
    "rumor_class = len(rumor)*[1]\n",
    "reverse_class = len(reverse)*[0]\n",
    "data = rumor + reverse\n",
    "data_class = rumor_class + reverse_class\n",
    "#后续添加数据要放在raw目录下，使用.xlsx格式将后续标注的数据加入data\n",
    "raw_data_list = os.listdir('raw')\n",
    "data_list = []\n",
    "good_name = re.compile(r'^(?!(\\~\\$)).*(.xlsx)')\n",
    "for i in raw_data_list:\n",
    "    if good_name.match(i):\n",
    "    #    data_list.append(i)\n",
    "        temp = pd.read_excel('raw/'+i)\n",
    "        temp.fillna('',inplace=True)\n",
    "        temp_rumor = [x.strip() for x in  temp['punc_rumor'].to_list()  if x.strip()!='']\n",
    "        temp_reverse = [x.strip() for x in  temp['punc_truth'].to_list()  if x.strip()!='']\n",
    "        temp_rumor_class = len(temp_rumor)*[1]\n",
    "        temp_reverse_class = len(temp_reverse)*[0]\n",
    "        temp_data = temp_rumor + temp_reverse\n",
    "        temp_data_class = temp_rumor_class + temp_reverse_class\n",
    "        for i in range( len(temp_data)):\n",
    "            temp_data[i]=re.sub(r'[\\,\\'\\ ]|(\\n)','',temp_data[i])\n",
    "    data = data + temp_data\n",
    "    data_class = data_class + temp_data_class\n",
    "with open('data.txt','w') as f:\n",
    "    for i in range(len(data)):\n",
    "        f.write(data[i]+'\\t'+str(data_class[i])+'\\n')\n",
    "        data_list =list( zip(data, data_class))\n",
    "random.shuffle(data_list)\n",
    "data, data_class = zip(*data_list)\n",
    "index = ['rumor{}{}'.format(i, '!' * j) for (i, j) in zip(range(len(data)), data_class)]\n",
    "df = pd .DataFrame(data=zip(data_class,data), columns=[\"rumor\",\"text\"], index=index)\n",
    "\n",
    "# 去除停用词\n",
    "with open ('hit_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "\n",
    "# jieba分词\n",
    "import jieba\n",
    "for i in range(len(df)):\n",
    "    words = jieba.cut(df[\"text\"].iloc[i],cut_all=False)\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    df[\"text\"].iloc[i] = ' '.join(words) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 隐形狄利克雷分布原理\n",
    "- 设想一台自动生成文档的机器，只有两个选项来控制生成文档的两个属性\n",
    "    - 生成文档的词的数量（泊松分布）\n",
    "    - 文档中混合的主题的数量（狄利克雷分布）\n",
    "- 除此之外，最关键的问题在于确定一个主题-词项矩阵，该矩阵表示了每个词对主题的贡献权重。一但能够确定这个矩阵，机器就可以在选择好的主题上反复迭代选择词，直到生成一篇足够长度的文档。\n",
    "- 回到对现有文档估计主题的问题上来，LDiA可以用于关于词和主题的参数，Blei和Ng通过分析语料库中文档的统计数据确定两个参数\n",
    "    - 第一个参数可以通过计算语料库的平均词（n-gram）数量、\n",
    "    - 第二个参数更棘手，必须先猜测有几个主题数再为主题分配语词，最后优化目标函数\n",
    "-  “LSA试图将原本分散的东西分散开，LDiA试图将原本接近的东西接近在一起”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenyu/opt/anaconda3/envs/nlpiaenv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import casual_tokenize\n",
    "np.random.seed(42)\n",
    "\n",
    "counter = CountVectorizer(tokenizer=casual_tokenize)\n",
    "bow_docs = pd.DataFrame(counter.fit_transform(raw_documents=df.text)\n",
    "                        .toarray(), index=index)\n",
    "column_nums, terms = zip(*sorted(zip(counter.vocabulary_.values(),\n",
    "                                     counter.vocabulary_.keys())))\n",
    "bow_docs.columns = terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rumor0:抽烟 脑梗塞 肯定 关系 血管 收缩 之后 大脑皮层 供血会 减少 引起 血栓 风险 烟中 主要 成分 一氧化碳 有毒 气体 进入 体内 之后 会 损害 血管 内皮 内皮 受损 之后 会 引起 血小板 脂质 沉积 引起 动脉 粥样 硬化 动脉 粥样 硬化 严重 会 引起 血管 狭窄 会 引起 血压 升高 引起 毛孔 堵塞\n",
      "一氧化碳    1\n",
      "严重      1\n",
      "主要      1\n",
      "之后      3\n",
      "会       4\n",
      "Name: rumor0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print('rumor0:'+df.loc['rumor0'].text)\n",
    "    print(bow_docs.loc['rumor0'][bow_docs.loc['rumor0'] > 0].head())\n",
    "except KeyError:\n",
    "    print('rumor0!:'+df.loc['rumor0!'].text)\n",
    "    print(bow_docs.loc['rumor0!'][bow_docs.loc['rumor0!'] > 0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 7755)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDiA\n",
    "ldia = LDiA(n_components=16, learning_method='batch')\n",
    "ldia = ldia.fit(bow_docs)  # <1>\n",
    "ldia.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>1.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0t</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic0  \\\n",
       "%     1.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic1  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic2  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic3  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic4  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic5  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic6  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic7  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic8  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic9  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic10  \\\n",
       "%      0.06   \n",
       "0      0.06   \n",
       "0t     0.06   \n",
       "\n",
       "    topic11  \\\n",
       "%      0.06   \n",
       "0      0.06   \n",
       "0t     0.06   \n",
       "\n",
       "    topic12  \\\n",
       "%      0.06   \n",
       "0      0.06   \n",
       "0t     0.06   \n",
       "\n",
       "    topic13  \\\n",
       "%      0.06   \n",
       "0      0.06   \n",
       "0t     0.06   \n",
       "\n",
       "    topic14  \\\n",
       "%      0.06   \n",
       "0      1.06   \n",
       "0t     0.06   \n",
       "\n",
       "    topic15  \n",
       "%      0.06  \n",
       "0      0.06  \n",
       "0t     2.06  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['topic{}'.format(i) for i in range(ldia.components_.shape[0])]\n",
    "pd.set_option('display.width', 2)\n",
    "componets = pd.DataFrame(ldia.components_.T,index = terms ,columns=columns)\n",
    "componets.round(2).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "都      113.517404\n",
       "吃       60.327271\n",
       "控制      48.785821\n",
       "不       40.797531\n",
       "人       39.901666\n",
       "好       32.342396\n",
       "一定      32.236831\n",
       "糖尿病     29.405834\n",
       "这种      29.404623\n",
       "可能      29.204294\n",
       "Name: topic0, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "componets.topic0.sort_values(axis=0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        topic0  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic1  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic2  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic3  \\\n",
       "rumor0    0.00   \n",
       "rumor1    0.00   \n",
       "rumor2    0.00   \n",
       "rumor3    0.23   \n",
       "rumor4    0.11   \n",
       "\n",
       "        topic4  \\\n",
       "rumor0    0.33   \n",
       "rumor1    0.00   \n",
       "rumor2    0.00   \n",
       "rumor3    0.00   \n",
       "rumor4    0.00   \n",
       "\n",
       "        topic5  \\\n",
       "rumor0    0.00   \n",
       "rumor1    0.00   \n",
       "rumor2    0.00   \n",
       "rumor3    0.51   \n",
       "rumor4    0.00   \n",
       "\n",
       "        topic6  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic7  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic8  \\\n",
       "rumor0    0.66   \n",
       "rumor1    0.00   \n",
       "rumor2    0.00   \n",
       "rumor3    0.00   \n",
       "rumor4    0.00   \n",
       "\n",
       "        topic9  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic10  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic11  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic12  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.00   \n",
       "rumor2     0.00   \n",
       "rumor3     0.00   \n",
       "rumor4     0.88   \n",
       "\n",
       "        topic13  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.00   \n",
       "rumor2     0.00   \n",
       "rumor3     0.21   \n",
       "rumor4     0.00   \n",
       "\n",
       "        topic14  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.97   \n",
       "rumor2     0.96   \n",
       "rumor3     0.00   \n",
       "rumor4     0.00   \n",
       "\n",
       "        topic15  \n",
       "rumor0      0.0  \n",
       "rumor1      0.0  \n",
       "rumor2      0.0  \n",
       "rumor3      0.0  \n",
       "rumor4      0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia16_topic_vectors = ldia.transform(bow_docs)\n",
    "ldia16_topic_vectors = pd.DataFrame(ldia16_topic_vectors,\n",
    "                                    index=index, columns=columns)\n",
    "ldia16_topic_vectors.round(2).head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用LDiA主题向量训练LDA模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过采样前训练集中类别0的数量： 709\n",
      "过采样前训练集中类别1的数量： 243\n",
      "过采样后训练集中类别0的数量： 709\n",
      "过采样后训练集中类别1的数量： 709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.529"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(ldia16_topic_vectors,df.rumor,test_size=0.5,random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "# 进行过采样\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"过采样前训练集中类别0的数量：\", sum(y_train==0))\n",
    "print(\"过采样前训练集中类别1的数量：\", sum(y_train==1))\n",
    "\n",
    "print(\"过采样后训练集中类别0的数量：\", sum(y_train_res==0))\n",
    "print(\"过采样后训练集中类别1的数量：\", sum(y_train_res==1))\n",
    "lda = LDA()\n",
    "lda = lda.fit(X_train_res, y_train_res)\n",
    "df['ldia16_rumor'] = lda.predict(ldia16_topic_vectors)\n",
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对比TF-IDF向量的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenyu/opt/anaconda3/envs/nlpiaenv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import casual_tokenize\n",
    "tfidf = TfidfVectorizer(tokenizer=casual_tokenize,)\n",
    "tfidf_docs =tfidf.fit_transform(raw_documents=df.text).toarray()\n",
    "tfidf_docs = tfidf_docs - tfidf_docs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过采样前训练集中类别0的数量： 709\n",
      "过采样前训练集中类别1的数量： 243\n",
      "过采样后训练集中类别0的数量： 709\n",
      "过采样后训练集中类别1的数量： 709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.959"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(tfidf_docs,df.rumor,test_size=0.5,random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "# 进行过采样\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"过采样前训练集中类别0的数量：\", sum(y_train==0))\n",
    "print(\"过采样前训练集中类别1的数量：\", sum(y_train==1))\n",
    "\n",
    "print(\"过采样后训练集中类别0的数量：\", sum(y_train_res==0))\n",
    "print(\"过采样后训练集中类别1的数量：\", sum(y_train_res==1))\n",
    "lda = LDA()\n",
    "lda = lda.fit(X_train_res, y_train_res)\n",
    "round(float(lda.score(X_train, y_train)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.744"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Accuracy: 0.59 (+/- 0.04)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(lda, tfidf_docs, df.rumor, cv=5)\n",
    "\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDiA使用32个主题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 7755)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia32 = LDiA(n_components=32, learning_method='batch')\n",
    "ldia32 = ldia32.fit(bow_docs)\n",
    "ldia32.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic22</th>\n",
       "      <th>topic23</th>\n",
       "      <th>topic24</th>\n",
       "      <th>topic25</th>\n",
       "      <th>topic26</th>\n",
       "      <th>topic27</th>\n",
       "      <th>topic28</th>\n",
       "      <th>topic29</th>\n",
       "      <th>topic30</th>\n",
       "      <th>topic31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        topic0  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic1  \\\n",
       "rumor0    0.00   \n",
       "rumor1    0.00   \n",
       "rumor2    0.00   \n",
       "rumor3    0.43   \n",
       "rumor4    0.00   \n",
       "\n",
       "        topic2  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic3  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic4  \\\n",
       "rumor0    0.00   \n",
       "rumor1    0.00   \n",
       "rumor2    0.95   \n",
       "rumor3    0.00   \n",
       "rumor4    0.00   \n",
       "\n",
       "        topic5  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic6  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic7  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic8  \\\n",
       "rumor0    0.53   \n",
       "rumor1    0.00   \n",
       "rumor2    0.00   \n",
       "rumor3    0.00   \n",
       "rumor4    0.00   \n",
       "\n",
       "        topic9  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        ...  \\\n",
       "rumor0  ...   \n",
       "rumor1  ...   \n",
       "rumor2  ...   \n",
       "rumor3  ...   \n",
       "rumor4  ...   \n",
       "\n",
       "        topic22  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic23  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic24  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic25  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic26  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic27  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.00   \n",
       "rumor2     0.00   \n",
       "rumor3     0.51   \n",
       "rumor4     0.00   \n",
       "\n",
       "        topic28  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic29  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic30  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic31  \n",
       "rumor0     0.45  \n",
       "rumor1     0.00  \n",
       "rumor2     0.00  \n",
       "rumor3     0.00  \n",
       "rumor4     0.00  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia32_topic_vectors = ldia32.transform(bow_docs)\n",
    "columns32 = ['topic{}'.format(i) for i in range(ldia32.components_.shape[0])]\n",
    "ldia32_topic_vectors = pd.DataFrame(ldia32_topic_vectors,index=index, columns=columns32)\n",
    "ldia32_topic_vectors.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过采样前训练集中类别0的数量： 709\n",
      "过采样前训练集中类别1的数量： 243\n",
      "过采样后训练集中类别0的数量： 709\n",
      "过采样后训练集中类别1的数量： 709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.586"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(ldia32_topic_vectors,df.rumor,test_size=0.5,random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "# 进行过采样\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"过采样前训练集中类别0的数量：\", sum(y_train==0))\n",
    "print(\"过采样前训练集中类别1的数量：\", sum(y_train==1))\n",
    "\n",
    "print(\"过采样后训练集中类别0的数量：\", sum(y_train_res==0))\n",
    "print(\"过采样后训练集中类别1的数量：\", sum(y_train_res==1))\n",
    "lda = LDA()\n",
    "lda = lda.fit(X_train_res, y_train_res)\n",
    "df['ldia32_rumor'] = lda.predict(ldia32_topic_vectors)\n",
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpiaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
