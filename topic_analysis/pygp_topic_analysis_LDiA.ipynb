{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='your module name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f0/6j6j3w814n53skbt2s4d8p5m0000gn/T/ipykernel_36238/2493417845.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text\"].iloc[i] = ' '.join(words)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('smalldata_washed.csv')\n",
    "rumor = data['rumor'].to_list()\n",
    "reverse = data['reverse'].to_list()\n",
    "rumor_class = len(rumor)*[1]\n",
    "reverse_class = len(reverse)*[0]\n",
    "data = rumor + reverse\n",
    "data_class = rumor_class + reverse_class\n",
    "#后续添加数据要放在raw目录下，使用.xlsx格式将后续标注的数据加入data\n",
    "raw_data_list = os.listdir('raw')\n",
    "data_list = []\n",
    "good_name = re.compile(r'^(?!(\\~\\$)).*(.xlsx)')\n",
    "for i in raw_data_list:\n",
    "    if good_name.match(i):\n",
    "    #    data_list.append(i)\n",
    "        temp = pd.read_excel('raw/'+i)\n",
    "        temp.fillna('',inplace=True)\n",
    "        temp_rumor = [x.strip() for x in  temp['punc_rumor'].to_list()  if x.strip()!='']\n",
    "        temp_reverse = [x.strip() for x in  temp['punc_truth'].to_list()  if x.strip()!='']\n",
    "        temp_rumor_class = len(temp_rumor)*[1]\n",
    "        temp_reverse_class = len(temp_reverse)*[0]\n",
    "        temp_data = temp_rumor + temp_reverse\n",
    "        temp_data_class = temp_rumor_class + temp_reverse_class\n",
    "        for i in range( len(temp_data)):\n",
    "            temp_data[i]=re.sub(r'[\\,\\'\\ ]|(\\n)','',temp_data[i])\n",
    "    data = data + temp_data\n",
    "    data_class = data_class + temp_data_class\n",
    "with open('data.txt','w') as f:\n",
    "    for i in range(len(data)):\n",
    "        f.write(data[i]+'\\t'+str(data_class[i])+'\\n')\n",
    "        data_list =list( zip(data, data_class))\n",
    "random.shuffle(data_list)\n",
    "data, data_class = zip(*data_list)\n",
    "index = ['rumor{}{}'.format(i, '!' * j) for (i, j) in zip(range(len(data)), data_class)]\n",
    "df = pd .DataFrame(data=zip(data_class,data), columns=[\"rumor\",\"text\"], index=index)\n",
    "\n",
    "# 去除停用词\n",
    "with open ('hit_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "\n",
    "# jieba分词\n",
    "import jieba\n",
    "for i in range(len(df)):\n",
    "    words = jieba.cut(df[\"text\"].iloc[i],cut_all=False)\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    df[\"text\"].iloc[i] = ' '.join(words) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 隐形狄利克雷分布原理\n",
    "- 设想一台自动生成文档的机器，只有两个选项来控制生成文档的两个属性\n",
    "    - 生成文档的词的数量（泊松分布）\n",
    "    - 文档中混合的主题的数量（狄利克雷分布）\n",
    "- 除此之外，最关键的问题在于确定一个主题-词项矩阵，该矩阵表示了每个词对主题的贡献权重。一但能够确定这个矩阵，机器就可以在选择好的主题上反复迭代选择词，直到生成一篇足够长度的文档。\n",
    "- 回到对现有文档估计主题的问题上来，LDiA可以用于关于词和主题的参数，Blei和Ng通过分析语料库中文档的统计数据确定两个参数\n",
    "    - 第一个参数可以通过计算语料库的平均词（n-gram）数量、\n",
    "    - 第二个参数更棘手，必须先猜测有几个主题数再为主题分配语词，最后优化目标函数\n",
    "-  “LSA试图将原本分散的东西分散开，LDiA试图将原本接近的东西接近在一起”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenyu/opt/anaconda3/envs/d2l/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import casual_tokenize\n",
    "np.random.seed(42)\n",
    "\n",
    "counter = CountVectorizer(tokenizer=casual_tokenize)\n",
    "bow_docs = pd.DataFrame(counter.fit_transform(raw_documents=df.text)\n",
    "                        .toarray(), index=index)\n",
    "column_nums, terms = zip(*sorted(zip(counter.vocabulary_.values(),\n",
    "                                     counter.vocabulary_.keys())))\n",
    "bow_docs.columns = terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rumor0:长期 高血压 不 好好 控制 这次 发生 心梗 普通 病人 出现 这种 心梗 长期 高血压 控制 不好 心脏 压力 过大 心脏 结构 发生 变化 都 认为 很 危险 脏 导管 指引 导管 都 很 难 到位 做成 手段 非常 非常 困难 一部分 高血压 病人 冠脉 特点 不够 卖 变得 很 曲 求全 触发 某种 正常 很 平直 包括 支架 植入 都 相对 来讲 会 比较顺利 导管 都 是从 正常 心脏 结构设计 标准 更 一台 急诊 手术 衣服 都 湿透 全身 汗 太难 做 病人 死者 完 可能 根本 做不了 介入 手术\n",
      "一台     1\n",
      "一部分    1\n",
      "不      1\n",
      "不够     1\n",
      "不好     1\n",
      "Name: rumor0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print('rumor0:'+df.loc['rumor0'].text)\n",
    "    print(bow_docs.loc['rumor0'][bow_docs.loc['rumor0'] > 0].head())\n",
    "except KeyError:\n",
    "    print('rumor0!:'+df.loc['rumor0!'].text)\n",
    "    print(bow_docs.loc['rumor0!'][bow_docs.loc['rumor0!'] > 0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 9142)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDiA\n",
    "ldia = LDiA(n_components=16, learning_method='batch')\n",
    "ldia = ldia.fit(bow_docs)  # <1>\n",
    "ldia.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>0.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0t</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic0  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic1  \\\n",
       "%     1.06   \n",
       "0     1.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic2  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic3  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic4  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic5  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic6  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic7  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic8  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic9  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    2.06   \n",
       "\n",
       "    topic10  \\\n",
       "%      0.06   \n",
       "0      0.06   \n",
       "0t     0.06   \n",
       "\n",
       "    topic11  \\\n",
       "%      0.06   \n",
       "0      0.06   \n",
       "0t     0.06   \n",
       "\n",
       "    topic12  \\\n",
       "%      0.06   \n",
       "0      0.06   \n",
       "0t     0.06   \n",
       "\n",
       "    topic13  \\\n",
       "%      0.06   \n",
       "0      0.06   \n",
       "0t     0.06   \n",
       "\n",
       "    topic14  \\\n",
       "%      0.06   \n",
       "0      0.06   \n",
       "0t     0.06   \n",
       "\n",
       "    topic15  \n",
       "%      0.06  \n",
       "0      0.06  \n",
       "0t     0.06  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['topic{}'.format(i) for i in range(ldia.components_.shape[0])]\n",
    "pd.set_option('display.width', 2)\n",
    "componets = pd.DataFrame(ldia.components_.T,index = terms ,columns=columns)\n",
    "componets.round(2).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "会     216.050523\n",
       "都     100.898608\n",
       "出现    100.566663\n",
       "可能     87.019894\n",
       "不      76.876138\n",
       "没有     67.348195\n",
       "血管     65.748018\n",
       "头痛     57.849745\n",
       "症状     57.702520\n",
       "说      51.045722\n",
       "Name: topic0, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "componets.topic0.sort_values(axis=0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3!</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic0  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.12   \n",
       "rumor2     0.00   \n",
       "rumor3!    0.01   \n",
       "rumor4     0.00   \n",
       "\n",
       "         topic1  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.01   \n",
       "rumor2     0.00   \n",
       "rumor3!    0.01   \n",
       "rumor4     0.61   \n",
       "\n",
       "         topic2  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.01   \n",
       "rumor2     0.55   \n",
       "rumor3!    0.81   \n",
       "rumor4     0.00   \n",
       "\n",
       "         topic3  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.01   \n",
       "rumor2     0.00   \n",
       "rumor3!    0.01   \n",
       "rumor4     0.00   \n",
       "\n",
       "         topic4  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.01   \n",
       "rumor2     0.00   \n",
       "rumor3!    0.01   \n",
       "rumor4     0.00   \n",
       "\n",
       "         topic5  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.01   \n",
       "rumor2     0.00   \n",
       "rumor3!    0.01   \n",
       "rumor4     0.00   \n",
       "\n",
       "         topic6  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.79   \n",
       "rumor2     0.00   \n",
       "rumor3!    0.01   \n",
       "rumor4     0.00   \n",
       "\n",
       "         topic7  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.01   \n",
       "rumor2     0.00   \n",
       "rumor3!    0.01   \n",
       "rumor4     0.00   \n",
       "\n",
       "         topic8  \\\n",
       "rumor0     0.14   \n",
       "rumor1     0.01   \n",
       "rumor2     0.00   \n",
       "rumor3!    0.01   \n",
       "rumor4     0.00   \n",
       "\n",
       "         topic9  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.01   \n",
       "rumor2     0.00   \n",
       "rumor3!    0.01   \n",
       "rumor4     0.00   \n",
       "\n",
       "         topic10  \\\n",
       "rumor0      0.00   \n",
       "rumor1      0.01   \n",
       "rumor2      0.00   \n",
       "rumor3!     0.01   \n",
       "rumor4      0.00   \n",
       "\n",
       "         topic11  \\\n",
       "rumor0      0.00   \n",
       "rumor1      0.01   \n",
       "rumor2      0.00   \n",
       "rumor3!     0.01   \n",
       "rumor4      0.00   \n",
       "\n",
       "         topic12  \\\n",
       "rumor0      0.85   \n",
       "rumor1      0.01   \n",
       "rumor2      0.40   \n",
       "rumor3!     0.01   \n",
       "rumor4      0.00   \n",
       "\n",
       "         topic13  \\\n",
       "rumor0      0.00   \n",
       "rumor1      0.01   \n",
       "rumor2      0.00   \n",
       "rumor3!     0.01   \n",
       "rumor4      0.33   \n",
       "\n",
       "         topic14  \\\n",
       "rumor0      0.00   \n",
       "rumor1      0.01   \n",
       "rumor2      0.00   \n",
       "rumor3!     0.01   \n",
       "rumor4      0.00   \n",
       "\n",
       "         topic15  \n",
       "rumor0      0.00  \n",
       "rumor1      0.01  \n",
       "rumor2      0.00  \n",
       "rumor3!     0.01  \n",
       "rumor4      0.00  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia16_topic_vectors = ldia.transform(bow_docs)\n",
    "ldia16_topic_vectors = pd.DataFrame(ldia16_topic_vectors,\n",
    "                                    index=index, columns=columns)\n",
    "ldia16_topic_vectors.round(2).head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用LDiA主题向量训练LDA模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过采样前训练集中类别0的数量： 1540\n",
      "过采样前训练集中类别1的数量： 452\n",
      "过采样后训练集中类别0的数量： 1540\n",
      "过采样后训练集中类别1的数量： 1540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.556"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(ldia16_topic_vectors,df.rumor,test_size=0.2,random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "# 进行过采样\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"过采样前训练集中类别0的数量：\", sum(y_train==0))\n",
    "print(\"过采样前训练集中类别1的数量：\", sum(y_train==1))\n",
    "\n",
    "print(\"过采样后训练集中类别0的数量：\", sum(y_train_res==0))\n",
    "print(\"过采样后训练集中类别1的数量：\", sum(y_train_res==1))\n",
    "lda = LDA()\n",
    "lda = lda.fit(X_train_res, y_train_res)\n",
    "df['ldia16_rumor'] = lda.predict(ldia16_topic_vectors)\n",
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rumor1057',\n",
      "       'rumor478',\n",
      "       'rumor976',\n",
      "       'rumor422',\n",
      "       'rumor1399',\n",
      "       'rumor1447',\n",
      "       'rumor2329!',\n",
      "       'rumor1937',\n",
      "       'rumor2064',\n",
      "       'rumor2476',\n",
      "       ...\n",
      "       'rumor1847',\n",
      "       'rumor1146!',\n",
      "       'rumor461',\n",
      "       'rumor109',\n",
      "       'rumor1943',\n",
      "       'rumor354',\n",
      "       'rumor266',\n",
      "       'rumor889',\n",
      "       'rumor1553',\n",
      "       'rumor564'],\n",
      "      dtype='object', length=498)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      非rumor     0.8299    0.5880    0.6883       415\n",
      "       rumor     0.1618    0.3976    0.2300        83\n",
      "\n",
      "    accuracy                         0.5562       498\n",
      "   macro avg     0.4958    0.4928    0.4591       498\n",
      "weighted avg     0.7186    0.5562    0.6119       498\n",
      "\n",
      "[[244 171]\n",
      " [ 50  33]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "y_true = df.loc[y_test.index].rumor\n",
    "y_pred = df.loc[y_test.index].ldia16_rumor\n",
    "loss_total = 0\n",
    "acc = metrics.accuracy_score(y_true, y_pred)\n",
    "report = metrics.classification_report(y_true, y_pred, target_names=[\"非rumor\",\"rumor\"], digits=4)\n",
    "confusion = metrics.confusion_matrix(y_true, y_pred)\n",
    "print(report)\n",
    "print(confusion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对比TF-IDF向量的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenyu/opt/anaconda3/envs/d2l/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import casual_tokenize\n",
    "tfidf = TfidfVectorizer(tokenizer=casual_tokenize,)\n",
    "tfidf_docs =tfidf.fit_transform(raw_documents=df.text).toarray()\n",
    "tfidf_docs = tfidf_docs - tfidf_docs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过采样前训练集中类别0的数量： 1540\n",
      "过采样前训练集中类别1的数量： 452\n",
      "过采样后训练集中类别0的数量： 1540\n",
      "过采样后训练集中类别1的数量： 1540\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(tfidf_docs,df.rumor,test_size=0.2,random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "# 进行过采样\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"过采样前训练集中类别0的数量：\", sum(y_train==0))\n",
    "print(\"过采样前训练集中类别1的数量：\", sum(y_train==1))\n",
    "\n",
    "print(\"过采样后训练集中类别0的数量：\", sum(y_train_res==0))\n",
    "print(\"过采样后训练集中类别1的数量：\", sum(y_train_res==1))\n",
    "lda = LDA()\n",
    "lda = lda.fit(X_train_res, y_train_res)\n",
    "df['tfidf_rumor'] = lda.predict(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.779"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      非rumor     0.9320    0.7928    0.8568       415\n",
      "       rumor     0.4069    0.7108    0.5175        83\n",
      "\n",
      "    accuracy                         0.7791       498\n",
      "   macro avg     0.6695    0.7518    0.6872       498\n",
      "weighted avg     0.8445    0.7791    0.8002       498\n",
      "\n",
      "[[329  86]\n",
      " [ 24  59]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "y_true = df.loc[y_test.index].rumor\n",
    "y_pred = df.loc[y_test.index].tfidf_rumor\n",
    "loss_total = 0\n",
    "acc = metrics.accuracy_score(y_true, y_pred)\n",
    "report = metrics.classification_report(y_true, y_pred, target_names=[\"非rumor\",\"rumor\"], digits=4)\n",
    "confusion = metrics.confusion_matrix(y_true, y_pred)\n",
    "print(report)\n",
    "print(confusion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDiA使用32个主题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 9142)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia32 = LDiA(n_components=100, learning_method='batch')\n",
    "ldia32 = ldia32.fit(bow_docs)\n",
    "ldia32.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic90</th>\n",
       "      <th>topic91</th>\n",
       "      <th>topic92</th>\n",
       "      <th>topic93</th>\n",
       "      <th>topic94</th>\n",
       "      <th>topic95</th>\n",
       "      <th>topic96</th>\n",
       "      <th>topic97</th>\n",
       "      <th>topic98</th>\n",
       "      <th>topic99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3!</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic0  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3!     0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "         topic1  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3!     0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "         topic2  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3!     0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "         topic3  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3!     0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "         topic4  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3!     0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "         topic5  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3!     0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "         topic6  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3!     0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "         topic7  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3!     0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "         topic8  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3!     0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "         topic9  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3!     0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "         ...  \\\n",
       "rumor0   ...   \n",
       "rumor1   ...   \n",
       "rumor2   ...   \n",
       "rumor3!  ...   \n",
       "rumor4   ...   \n",
       "\n",
       "         topic90  \\\n",
       "rumor0       0.0   \n",
       "rumor1       0.0   \n",
       "rumor2       0.0   \n",
       "rumor3!      0.0   \n",
       "rumor4       0.0   \n",
       "\n",
       "         topic91  \\\n",
       "rumor0       0.0   \n",
       "rumor1       0.0   \n",
       "rumor2       0.0   \n",
       "rumor3!      0.0   \n",
       "rumor4       0.0   \n",
       "\n",
       "         topic92  \\\n",
       "rumor0       0.0   \n",
       "rumor1       0.0   \n",
       "rumor2       0.0   \n",
       "rumor3!      0.0   \n",
       "rumor4       0.0   \n",
       "\n",
       "         topic93  \\\n",
       "rumor0       0.0   \n",
       "rumor1       0.0   \n",
       "rumor2       0.0   \n",
       "rumor3!      0.0   \n",
       "rumor4       0.0   \n",
       "\n",
       "         topic94  \\\n",
       "rumor0       0.0   \n",
       "rumor1       0.0   \n",
       "rumor2       0.0   \n",
       "rumor3!      0.0   \n",
       "rumor4       0.0   \n",
       "\n",
       "         topic95  \\\n",
       "rumor0       0.0   \n",
       "rumor1       0.0   \n",
       "rumor2       0.0   \n",
       "rumor3!      0.0   \n",
       "rumor4       0.0   \n",
       "\n",
       "         topic96  \\\n",
       "rumor0       0.0   \n",
       "rumor1       0.0   \n",
       "rumor2       0.0   \n",
       "rumor3!      0.0   \n",
       "rumor4       0.0   \n",
       "\n",
       "         topic97  \\\n",
       "rumor0       0.0   \n",
       "rumor1       0.0   \n",
       "rumor2       0.0   \n",
       "rumor3!      0.0   \n",
       "rumor4       0.0   \n",
       "\n",
       "         topic98  \\\n",
       "rumor0       0.0   \n",
       "rumor1       0.0   \n",
       "rumor2       0.0   \n",
       "rumor3!      0.0   \n",
       "rumor4       0.0   \n",
       "\n",
       "         topic99  \n",
       "rumor0       0.0  \n",
       "rumor1       0.0  \n",
       "rumor2       0.0  \n",
       "rumor3!      0.0  \n",
       "rumor4       0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia32_topic_vectors = ldia32.transform(bow_docs)\n",
    "columns32 = ['topic{}'.format(i) for i in range(ldia32.components_.shape[0])]\n",
    "ldia32_topic_vectors = pd.DataFrame(ldia32_topic_vectors,index=index, columns=columns32)\n",
    "ldia32_topic_vectors.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过采样前训练集中类别0的数量： 1540\n",
      "过采样前训练集中类别1的数量： 452\n",
      "过采样后训练集中类别0的数量： 1540\n",
      "过采样后训练集中类别1的数量： 1540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.56"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(ldia32_topic_vectors,df.rumor,test_size=0.2,random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "# 进行过采样\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"过采样前训练集中类别0的数量：\", sum(y_train==0))\n",
    "print(\"过采样前训练集中类别1的数量：\", sum(y_train==1))\n",
    "\n",
    "print(\"过采样后训练集中类别0的数量：\", sum(y_train_res==0))\n",
    "print(\"过采样后训练集中类别1的数量：\", sum(y_train_res==1))\n",
    "lda = LDA()\n",
    "lda = lda.fit(X_train_res, y_train_res)\n",
    "df['ldia32_rumor'] = lda.predict(ldia32_topic_vectors)\n",
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   non-rumor     0.8577    0.5663    0.6821       415\n",
      "       rumor     0.1964    0.5301    0.2866        83\n",
      "\n",
      "    accuracy                         0.5602       498\n",
      "   macro avg     0.5270    0.5482    0.4844       498\n",
      "weighted avg     0.7475    0.5602    0.6162       498\n",
      "\n",
      "[[235 180]\n",
      " [ 39  44]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "y_true = df.loc[y_test.index].rumor\n",
    "y_pred = df.loc[y_test.index].ldia32_rumor\n",
    "loss_total = 0\n",
    "acc = metrics.accuracy_score(y_true, y_pred)\n",
    "report = metrics.classification_report(y_true, y_pred, target_names=[\"non-rumor\",\"rumor\"], digits=4)\n",
    "confusion = metrics.confusion_matrix(y_true, y_pred)\n",
    "print(report)\n",
    "print(confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6d40a5097db4c11f3975da84c5456511726d6f156896da7e31bb0c17b283947"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
