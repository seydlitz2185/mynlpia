{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='your module name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f0/6j6j3w814n53skbt2s4d8p5m0000gn/T/ipykernel_36238/2493417845.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text\"].iloc[i] = ' '.join(words)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('smalldata_washed.csv')\n",
    "rumor = data['rumor'].to_list()\n",
    "reverse = data['reverse'].to_list()\n",
    "rumor_class = len(rumor)*[1]\n",
    "reverse_class = len(reverse)*[0]\n",
    "data = rumor + reverse\n",
    "data_class = rumor_class + reverse_class\n",
    "#后续添加数据要放在raw目录下，使用.xlsx格式将后续标注的数据加入data\n",
    "raw_data_list = os.listdir('raw')\n",
    "data_list = []\n",
    "good_name = re.compile(r'^(?!(\\~\\$)).*(.xlsx)')\n",
    "for i in raw_data_list:\n",
    "    if good_name.match(i):\n",
    "    #    data_list.append(i)\n",
    "        temp = pd.read_excel('raw/'+i)\n",
    "        temp.fillna('',inplace=True)\n",
    "        temp_rumor = [x.strip() for x in  temp['punc_rumor'].to_list()  if x.strip()!='']\n",
    "        temp_reverse = [x.strip() for x in  temp['punc_truth'].to_list()  if x.strip()!='']\n",
    "        temp_rumor_class = len(temp_rumor)*[1]\n",
    "        temp_reverse_class = len(temp_reverse)*[0]\n",
    "        temp_data = temp_rumor + temp_reverse\n",
    "        temp_data_class = temp_rumor_class + temp_reverse_class\n",
    "        for i in range( len(temp_data)):\n",
    "            temp_data[i]=re.sub(r'[\\,\\'\\ ]|(\\n)','',temp_data[i])\n",
    "    data = data + temp_data\n",
    "    data_class = data_class + temp_data_class\n",
    "with open('data.txt','w') as f:\n",
    "    for i in range(len(data)):\n",
    "        f.write(data[i]+'\\t'+str(data_class[i])+'\\n')\n",
    "        data_list =list( zip(data, data_class))\n",
    "random.shuffle(data_list)\n",
    "data, data_class = zip(*data_list)\n",
    "index = ['rumor{}{}'.format(i, '!' * j) for (i, j) in zip(range(len(data)), data_class)]\n",
    "df = pd .DataFrame(data=zip(data_class,data), columns=[\"rumor\",\"text\"], index=index)\n",
    "\n",
    "# 去除停用词\n",
    "with open ('hit_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "\n",
    "# jieba分词\n",
    "import jieba\n",
    "for i in range(len(df)):\n",
    "    words = jieba.cut(df[\"text\"].iloc[i],cut_all=False)\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    df[\"text\"].iloc[i] = ' '.join(words) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 隐形狄利克雷分布原理\n",
    "- 设想一台自动生成文档的机器，只有两个选项来控制生成文档的两个属性\n",
    "    - 生成文档的词的数量（泊松分布）\n",
    "    - 文档中混合的主题的数量（狄利克雷分布）\n",
    "- 除此之外，最关键的问题在于确定一个主题-词项矩阵，该矩阵表示了每个词对主题的贡献权重。一但能够确定这个矩阵，机器就可以在选择好的主题上反复迭代选择词，直到生成一篇足够长度的文档。\n",
    "- 回到对现有文档估计主题的问题上来，LDiA可以用于关于词和主题的参数，Blei和Ng通过分析语料库中文档的统计数据确定两个参数\n",
    "    - 第一个参数可以通过计算语料库的平均词（n-gram）数量、\n",
    "    - 第二个参数更棘手，必须先猜测有几个主题数再为主题分配语词，最后优化目标函数\n",
    "-  “LSA试图将原本分散的东西分散开，LDiA试图将原本接近的东西接近在一起”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenyu/opt/anaconda3/envs/d2l/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import casual_tokenize\n",
    "np.random.seed(42)\n",
    "\n",
    "counter = CountVectorizer(tokenizer=casual_tokenize)\n",
    "bow_docs = pd.DataFrame(counter.fit_transform(raw_documents=df.text)\n",
    "                        .toarray(), index=index)\n",
    "column_nums, terms = zip(*sorted(zip(counter.vocabulary_.values(),\n",
    "                                     counter.vocabulary_.keys())))\n",
    "bow_docs.columns = terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rumor0:已经 植入 心脏 支架 患者 一定 坚持 正规 西药 抗 血小板 治疗 不可 中药 代替 支架 内 发生 再 狭窄 堵塞 概率 将会 极大 增加 诱发 急性 心肌梗死\n",
      "一定    1\n",
      "不可    1\n",
      "中药    1\n",
      "代替    1\n",
      "内     1\n",
      "Name: rumor0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print('rumor0:'+df.loc['rumor0'].text)\n",
    "    print(bow_docs.loc['rumor0'][bow_docs.loc['rumor0'] > 0].head())\n",
    "except KeyError:\n",
    "    print('rumor0!:'+df.loc['rumor0!'].text)\n",
    "    print(bow_docs.loc['rumor0!'][bow_docs.loc['rumor0!'] > 0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 9142)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDiA\n",
    "ldia = LDiA(n_components=16, learning_method='batch')\n",
    "ldia = ldia.fit(bow_docs)  # <1>\n",
    "ldia.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0t</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic0  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic1  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic2  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic3  \\\n",
       "%     0.06   \n",
       "0     1.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic4  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic5  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic6  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic7  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic8  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    0.06   \n",
       "\n",
       "    topic9  \\\n",
       "%     0.06   \n",
       "0     0.06   \n",
       "0t    2.06   \n",
       "\n",
       "    topic10  \\\n",
       "%      0.06   \n",
       "0      0.06   \n",
       "0t     0.06   \n",
       "\n",
       "    topic11  \\\n",
       "%      0.06   \n",
       "0      0.06   \n",
       "0t     0.06   \n",
       "\n",
       "    topic12  \\\n",
       "%      0.06   \n",
       "0      0.06   \n",
       "0t     0.06   \n",
       "\n",
       "    topic13  \\\n",
       "%      0.06   \n",
       "0      0.06   \n",
       "0t     0.06   \n",
       "\n",
       "    topic14  \\\n",
       "%      1.06   \n",
       "0      0.06   \n",
       "0t     0.06   \n",
       "\n",
       "    topic15  \n",
       "%      0.06  \n",
       "0      0.06  \n",
       "0t     0.06  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['topic{}'.format(i) for i in range(ldia.components_.shape[0])]\n",
    "pd.set_option('display.width', 2)\n",
    "componets = pd.DataFrame(ldia.components_.T,index = terms ,columns=columns)\n",
    "componets.round(2).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "会     200.351333\n",
       "出现    106.214661\n",
       "都      86.943403\n",
       "可能     77.964169\n",
       "不      68.163753\n",
       "这种     56.155247\n",
       "心脏     55.547909\n",
       "症状     54.703698\n",
       "头痛     53.381958\n",
       "没有     50.712851\n",
       "Name: topic0, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "componets.topic0.sort_values(axis=0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        topic0  \\\n",
       "rumor0    0.00   \n",
       "rumor1    0.00   \n",
       "rumor2    0.00   \n",
       "rumor3    0.00   \n",
       "rumor4    0.75   \n",
       "\n",
       "        topic1  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic2  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic3  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic4  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic5  \\\n",
       "rumor0    0.00   \n",
       "rumor1    0.83   \n",
       "rumor2    0.00   \n",
       "rumor3    0.00   \n",
       "rumor4    0.23   \n",
       "\n",
       "        topic6  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic7  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic8  \\\n",
       "rumor0    0.21   \n",
       "rumor1    0.00   \n",
       "rumor2    0.28   \n",
       "rumor3    0.00   \n",
       "rumor4    0.00   \n",
       "\n",
       "        topic9  \\\n",
       "rumor0    0.46   \n",
       "rumor1    0.00   \n",
       "rumor2    0.00   \n",
       "rumor3    0.00   \n",
       "rumor4    0.00   \n",
       "\n",
       "        topic10  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic11  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic12  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.00   \n",
       "rumor2     0.00   \n",
       "rumor3     0.99   \n",
       "rumor4     0.00   \n",
       "\n",
       "        topic13  \\\n",
       "rumor0     0.31   \n",
       "rumor1     0.13   \n",
       "rumor2     0.00   \n",
       "rumor3     0.00   \n",
       "rumor4     0.00   \n",
       "\n",
       "        topic14  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic15  \n",
       "rumor0      0.0  \n",
       "rumor1      0.0  \n",
       "rumor2      0.7  \n",
       "rumor3      0.0  \n",
       "rumor4      0.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia16_topic_vectors = ldia.transform(bow_docs)\n",
    "ldia16_topic_vectors = pd.DataFrame(ldia16_topic_vectors,\n",
    "                                    index=index, columns=columns)\n",
    "ldia16_topic_vectors.round(2).head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用LDiA主题向量训练LDA模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过采样前训练集中类别0的数量： 1576\n",
      "过采样前训练集中类别1的数量： 416\n",
      "过采样后训练集中类别0的数量： 1576\n",
      "过采样后训练集中类别1的数量： 1576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.538"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(ldia16_topic_vectors,df.rumor,test_size=0.2,random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "# 进行过采样\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"过采样前训练集中类别0的数量：\", sum(y_train==0))\n",
    "print(\"过采样前训练集中类别1的数量：\", sum(y_train==1))\n",
    "\n",
    "print(\"过采样后训练集中类别0的数量：\", sum(y_train_res==0))\n",
    "print(\"过采样后训练集中类别1的数量：\", sum(y_train_res==1))\n",
    "lda = LDA()\n",
    "lda = lda.fit(X_train_res, y_train_res)\n",
    "df['ldia16_rumor'] = lda.predict(ldia16_topic_vectors)\n",
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rumor1057',\n",
      "       'rumor478',\n",
      "       'rumor976',\n",
      "       'rumor422!',\n",
      "       'rumor1399',\n",
      "       'rumor1447',\n",
      "       'rumor2329!',\n",
      "       'rumor1937!',\n",
      "       'rumor2064!',\n",
      "       'rumor2476',\n",
      "       ...\n",
      "       'rumor1847',\n",
      "       'rumor1146!',\n",
      "       'rumor461',\n",
      "       'rumor109',\n",
      "       'rumor1943!',\n",
      "       'rumor354',\n",
      "       'rumor266!',\n",
      "       'rumor889!',\n",
      "       'rumor1553',\n",
      "       'rumor564'],\n",
      "      dtype='object', length=498)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      非rumor     0.8197    0.5040    0.6242       379\n",
      "       rumor     0.2906    0.6471    0.4010       119\n",
      "\n",
      "    accuracy                         0.5382       498\n",
      "   macro avg     0.5552    0.5755    0.5126       498\n",
      "weighted avg     0.6933    0.5382    0.5709       498\n",
      "\n",
      "[[191 188]\n",
      " [ 42  77]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "y_true = df.loc[y_test.index].rumor\n",
    "y_pred = df.loc[y_test.index].ldia16_rumor\n",
    "loss_total = 0\n",
    "acc = metrics.accuracy_score(y_true, y_pred)\n",
    "report = metrics.classification_report(y_true, y_pred, target_names=[\"非rumor\",\"rumor\"], digits=4)\n",
    "confusion = metrics.confusion_matrix(y_true, y_pred)\n",
    "print(report)\n",
    "print(confusion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对比TF-IDF向量的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenyu/opt/anaconda3/envs/d2l/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import casual_tokenize\n",
    "tfidf = TfidfVectorizer(tokenizer=casual_tokenize,)\n",
    "tfidf_docs =tfidf.fit_transform(raw_documents=df.text).toarray()\n",
    "tfidf_docs = tfidf_docs - tfidf_docs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过采样前训练集中类别0的数量： 1558\n",
      "过采样前训练集中类别1的数量： 434\n",
      "过采样后训练集中类别0的数量： 1558\n",
      "过采样后训练集中类别1的数量： 1558\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(tfidf_docs,df.rumor,test_size=0.2,random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "# 进行过采样\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"过采样前训练集中类别0的数量：\", sum(y_train==0))\n",
    "print(\"过采样前训练集中类别1的数量：\", sum(y_train==1))\n",
    "\n",
    "print(\"过采样后训练集中类别0的数量：\", sum(y_train_res==0))\n",
    "print(\"过采样后训练集中类别1的数量：\", sum(y_train_res==1))\n",
    "lda = LDA()\n",
    "lda = lda.fit(X_train_res, y_train_res)\n",
    "df['tfidf_rumor'] = lda.predict(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.789"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         非谣言     0.9827    0.9591    0.9707      1955\n",
      "          谣言     0.8625    0.9383    0.8988       535\n",
      "\n",
      "    accuracy                         0.9546      2490\n",
      "   macro avg     0.9226    0.9487    0.9348      2490\n",
      "weighted avg     0.9569    0.9546    0.9553      2490\n",
      "\n",
      "[[1875   80]\n",
      " [  33  502]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "y_true = df.loc[y_test.index].rumor\n",
    "y_pred = df.loc[y_test.index].tfidf_rumor\n",
    "loss_total = 0\n",
    "acc = metrics.accuracy_score(y_true, y_pred)\n",
    "report = metrics.classification_report(y_true, y_pred, target_names=[\"非rumor\",\"rumor\"], digits=4)\n",
    "confusion = metrics.confusion_matrix(y_true, y_pred)\n",
    "print(report)\n",
    "print(confusion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDiA使用32个主题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 9142)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia32 = LDiA(n_components=100, learning_method='batch')\n",
    "ldia32 = ldia32.fit(bow_docs)\n",
    "ldia32.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic90</th>\n",
       "      <th>topic91</th>\n",
       "      <th>topic92</th>\n",
       "      <th>topic93</th>\n",
       "      <th>topic94</th>\n",
       "      <th>topic95</th>\n",
       "      <th>topic96</th>\n",
       "      <th>topic97</th>\n",
       "      <th>topic98</th>\n",
       "      <th>topic99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        topic0  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic1  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic2  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic3  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic4  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic5  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic6  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic7  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic8  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        topic9  \\\n",
       "rumor0     0.0   \n",
       "rumor1     0.0   \n",
       "rumor2     0.0   \n",
       "rumor3     0.0   \n",
       "rumor4     0.0   \n",
       "\n",
       "        ...  \\\n",
       "rumor0  ...   \n",
       "rumor1  ...   \n",
       "rumor2  ...   \n",
       "rumor3  ...   \n",
       "rumor4  ...   \n",
       "\n",
       "        topic90  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic91  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic92  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic93  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic94  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic95  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic96  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic97  \\\n",
       "rumor0      0.0   \n",
       "rumor1      0.0   \n",
       "rumor2      0.0   \n",
       "rumor3      0.0   \n",
       "rumor4      0.0   \n",
       "\n",
       "        topic98  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.00   \n",
       "rumor2     0.00   \n",
       "rumor3     0.09   \n",
       "rumor4     0.00   \n",
       "\n",
       "        topic99  \n",
       "rumor0      0.0  \n",
       "rumor1      0.0  \n",
       "rumor2      0.0  \n",
       "rumor3      0.0  \n",
       "rumor4      0.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia32_topic_vectors = ldia32.transform(bow_docs)\n",
    "columns32 = ['topic{}'.format(i) for i in range(ldia32.components_.shape[0])]\n",
    "ldia32_topic_vectors = pd.DataFrame(ldia32_topic_vectors,index=index, columns=columns32)\n",
    "ldia32_topic_vectors.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过采样前训练集中类别0的数量： 1558\n",
      "过采样前训练集中类别1的数量： 434\n",
      "过采样后训练集中类别0的数量： 1558\n",
      "过采样后训练集中类别1的数量： 1558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.512"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(ldia32_topic_vectors,df.rumor,test_size=0.2,random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "# 进行过采样\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"过采样前训练集中类别0的数量：\", sum(y_train==0))\n",
    "print(\"过采样前训练集中类别1的数量：\", sum(y_train==1))\n",
    "\n",
    "print(\"过采样后训练集中类别0的数量：\", sum(y_train_res==0))\n",
    "print(\"过采样后训练集中类别1的数量：\", sum(y_train_res==1))\n",
    "lda = LDA()\n",
    "lda = lda.fit(X_train_res, y_train_res)\n",
    "df['ldia32_rumor'] = lda.predict(ldia32_topic_vectors)\n",
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         非谣言     0.8527    0.6010    0.7051      1955\n",
      "          谣言     0.2986    0.6206    0.4032       535\n",
      "\n",
      "    accuracy                         0.6052      2490\n",
      "   macro avg     0.5756    0.6108    0.5541      2490\n",
      "weighted avg     0.7336    0.6052    0.6402      2490\n",
      "\n",
      "[[1175  780]\n",
      " [ 203  332]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "y_true = df.loc[y_test.index].rumor\n",
    "y_pred = df.loc[y_test.index].ldia32_rumor\n",
    "loss_total = 0\n",
    "acc = metrics.accuracy_score(y_true, y_pred)\n",
    "report = metrics.classification_report(y_true, y_pred, target_names=[\"non-rumor\",\"rumor\"], digits=4)\n",
    "confusion = metrics.confusion_matrix(y_true, y_pred)\n",
    "print(report)\n",
    "print(confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpiaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
