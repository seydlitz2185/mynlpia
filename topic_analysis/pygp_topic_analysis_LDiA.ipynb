{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='your module name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/f0/6j6j3w814n53skbt2s4d8p5m0000gn/T/jieba.cache\n",
      "Loading model cost 0.448 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "/var/folders/f0/6j6j3w814n53skbt2s4d8p5m0000gn/T/ipykernel_21642/2493417845.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text\"].iloc[i] = ' '.join(words)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('smalldata_washed.csv')\n",
    "rumor = data['rumor'].to_list()\n",
    "reverse = data['reverse'].to_list()\n",
    "rumor_class = len(rumor)*[1]\n",
    "reverse_class = len(reverse)*[0]\n",
    "data = rumor + reverse\n",
    "data_class = rumor_class + reverse_class\n",
    "#后续添加数据要放在raw目录下，使用.xlsx格式将后续标注的数据加入data\n",
    "raw_data_list = os.listdir('raw')\n",
    "data_list = []\n",
    "good_name = re.compile(r'^(?!(\\~\\$)).*(.xlsx)')\n",
    "for i in raw_data_list:\n",
    "    if good_name.match(i):\n",
    "    #    data_list.append(i)\n",
    "        temp = pd.read_excel('raw/'+i)\n",
    "        temp.fillna('',inplace=True)\n",
    "        temp_rumor = [x.strip() for x in  temp['punc_rumor'].to_list()  if x.strip()!='']\n",
    "        temp_reverse = [x.strip() for x in  temp['punc_truth'].to_list()  if x.strip()!='']\n",
    "        temp_rumor_class = len(temp_rumor)*[1]\n",
    "        temp_reverse_class = len(temp_reverse)*[0]\n",
    "        temp_data = temp_rumor + temp_reverse\n",
    "        temp_data_class = temp_rumor_class + temp_reverse_class\n",
    "        for i in range( len(temp_data)):\n",
    "            temp_data[i]=re.sub(r'[\\,\\'\\ ]|(\\n)','',temp_data[i])\n",
    "    data = data + temp_data\n",
    "    data_class = data_class + temp_data_class\n",
    "with open('data.txt','w') as f:\n",
    "    for i in range(len(data)):\n",
    "        f.write(data[i]+'\\t'+str(data_class[i])+'\\n')\n",
    "        data_list =list( zip(data, data_class))\n",
    "random.shuffle(data_list)\n",
    "data, data_class = zip(*data_list)\n",
    "index = ['rumor{}{}'.format(i, '!' * j) for (i, j) in zip(range(len(data)), data_class)]\n",
    "df = pd .DataFrame(data=zip(data_class,data), columns=[\"rumor\",\"text\"], index=index)\n",
    "\n",
    "# 去除停用词\n",
    "with open ('hit_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "\n",
    "# jieba分词\n",
    "import jieba\n",
    "for i in range(len(df)):\n",
    "    words = jieba.cut(df[\"text\"].iloc[i],cut_all=False)\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    df[\"text\"].iloc[i] = ' '.join(words) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 隐形狄利克雷分布原理\n",
    "- 设想一台自动生成文档的机器，只有两个选项来控制生成文档的两个属性\n",
    "    - 生成文档的词的数量（泊松分布）\n",
    "    - 文档中混合的主题的数量（狄利克雷分布）\n",
    "- 除此之外，最关键的问题在于确定一个主题-词项矩阵，该矩阵表示了每个词对主题的贡献权重。一但能够确定这个矩阵，机器就可以在选择好的主题上反复迭代选择词，直到生成一篇足够长度的文档。\n",
    "- 回到对现有文档估计主题的问题上来，LDiA可以用于关于词和主题的参数，Blei和Ng通过分析语料库中文档的统计数据确定两个参数\n",
    "    - 第一个参数可以通过计算语料库的平均词（n-gram）数量、\n",
    "    - 第二个参数更棘手，必须先猜测有几个主题数再为主题分配语词，最后优化目标函数\n",
    "-  “LSA试图将原本分散的东西分散开，LDiA试图将原本接近的东西接近在一起”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenyu/opt/anaconda3/envs/d2l/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import casual_tokenize\n",
    "np.random.seed(42)\n",
    "\n",
    "counter = CountVectorizer(tokenizer=casual_tokenize)\n",
    "bow_docs = pd.DataFrame(counter.fit_transform(raw_documents=df.text)\n",
    "                        .toarray(), index=index)\n",
    "column_nums, terms = zip(*sorted(zip(counter.vocabulary_.values(),\n",
    "                                     counter.vocabulary_.keys())))\n",
    "bow_docs.columns = terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rumor0:大家 都 胸闷 憋气 不 舒服 都 觉得 心脏 问题 不是 说 胸闷 憋气 检查 都 正常 行 胸口 疼 都 心脏 关系 游戏 中 女性 年轻 女性 很 可能 精神压力 大 医生 说 心脏 没事儿\n",
      "不     1\n",
      "不是    1\n",
      "中     1\n",
      "关系    1\n",
      "医生    1\n",
      "Name: rumor0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print('rumor0:'+df.loc['rumor0'].text)\n",
    "    print(bow_docs.loc['rumor0'][bow_docs.loc['rumor0'] > 0].head())\n",
    "except KeyError:\n",
    "    print('rumor0!:'+df.loc['rumor0!'].text)\n",
    "    print(bow_docs.loc['rumor0!'][bow_docs.loc['rumor0!'] > 0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 9200)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation as LDiA\n",
    "ldia = LDiA(n_components=16, learning_method='batch')\n",
    "ldia = ldia.fit(bow_docs)  # <1>\n",
    "ldia.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>%</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic0  \\\n",
       "%    0.06   \n",
       ".    0.06   \n",
       "0    0.06   \n",
       "\n",
       "   topic1  \\\n",
       "%    0.06   \n",
       ".    0.06   \n",
       "0    0.06   \n",
       "\n",
       "   topic2  \\\n",
       "%    0.06   \n",
       ".    0.06   \n",
       "0    0.06   \n",
       "\n",
       "   topic3  \\\n",
       "%    1.06   \n",
       ".    0.06   \n",
       "0    1.06   \n",
       "\n",
       "   topic4  \\\n",
       "%    0.06   \n",
       ".    0.06   \n",
       "0    0.06   \n",
       "\n",
       "   topic5  \\\n",
       "%    0.06   \n",
       ".    0.06   \n",
       "0    0.06   \n",
       "\n",
       "   topic6  \\\n",
       "%    0.06   \n",
       ".    0.06   \n",
       "0    0.06   \n",
       "\n",
       "   topic7  \\\n",
       "%    0.06   \n",
       ".    0.06   \n",
       "0    0.06   \n",
       "\n",
       "   topic8  \\\n",
       "%    0.06   \n",
       ".    0.06   \n",
       "0    0.06   \n",
       "\n",
       "   topic9  \\\n",
       "%    0.06   \n",
       ".    0.06   \n",
       "0    0.06   \n",
       "\n",
       "   topic10  \\\n",
       "%     0.06   \n",
       ".     0.06   \n",
       "0     0.06   \n",
       "\n",
       "   topic11  \\\n",
       "%     0.06   \n",
       ".     0.06   \n",
       "0     0.06   \n",
       "\n",
       "   topic12  \\\n",
       "%     0.06   \n",
       ".     1.06   \n",
       "0     0.06   \n",
       "\n",
       "   topic13  \\\n",
       "%     0.06   \n",
       ".     2.06   \n",
       "0     0.06   \n",
       "\n",
       "   topic14  \\\n",
       "%     0.06   \n",
       ".     0.06   \n",
       "0     0.06   \n",
       "\n",
       "   topic15  \n",
       "%     0.06  \n",
       ".     0.06  \n",
       "0     0.06  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['topic{}'.format(i) for i in range(ldia.components_.shape[0])]\n",
    "pd.set_option('display.width', 2)\n",
    "componets = pd.DataFrame(ldia.components_.T,index = terms ,columns=columns)\n",
    "componets.round(2).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "风险     126.779308\n",
       "会      104.137411\n",
       "降低      66.998038\n",
       "发生      66.390340\n",
       "糖尿病     52.532224\n",
       "发病      44.188418\n",
       "增加      41.142041\n",
       "引起      38.931123\n",
       "幽门      37.115259\n",
       "研究      31.756433\n",
       "Name: topic0, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "componets.topic0.sort_values(axis=0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>topic10</th>\n",
       "      <th>topic11</th>\n",
       "      <th>topic12</th>\n",
       "      <th>topic13</th>\n",
       "      <th>topic14</th>\n",
       "      <th>topic15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2!</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic0  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.00   \n",
       "rumor2!    0.01   \n",
       "rumor3     0.00   \n",
       "rumor4     0.00   \n",
       "\n",
       "         topic1  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.00   \n",
       "rumor2!    0.01   \n",
       "rumor3     0.00   \n",
       "rumor4     0.00   \n",
       "\n",
       "         topic2  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.00   \n",
       "rumor2!    0.01   \n",
       "rumor3     0.00   \n",
       "rumor4     0.00   \n",
       "\n",
       "         topic3  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.00   \n",
       "rumor2!    0.01   \n",
       "rumor3     0.00   \n",
       "rumor4     0.00   \n",
       "\n",
       "         topic4  \\\n",
       "rumor0     0.26   \n",
       "rumor1     0.00   \n",
       "rumor2!    0.01   \n",
       "rumor3     0.00   \n",
       "rumor4     0.00   \n",
       "\n",
       "         topic5  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.00   \n",
       "rumor2!    0.01   \n",
       "rumor3     0.00   \n",
       "rumor4     0.07   \n",
       "\n",
       "         topic6  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.00   \n",
       "rumor2!    0.01   \n",
       "rumor3     0.00   \n",
       "rumor4     0.00   \n",
       "\n",
       "         topic7  \\\n",
       "rumor0     0.72   \n",
       "rumor1     0.00   \n",
       "rumor2!    0.01   \n",
       "rumor3     0.00   \n",
       "rumor4     0.00   \n",
       "\n",
       "         topic8  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.00   \n",
       "rumor2!    0.84   \n",
       "rumor3     0.00   \n",
       "rumor4     0.00   \n",
       "\n",
       "         topic9  \\\n",
       "rumor0     0.00   \n",
       "rumor1     0.00   \n",
       "rumor2!    0.01   \n",
       "rumor3     0.00   \n",
       "rumor4     0.00   \n",
       "\n",
       "         topic10  \\\n",
       "rumor0      0.00   \n",
       "rumor1      0.00   \n",
       "rumor2!     0.01   \n",
       "rumor3      0.00   \n",
       "rumor4      0.00   \n",
       "\n",
       "         topic11  \\\n",
       "rumor0      0.00   \n",
       "rumor1      0.97   \n",
       "rumor2!     0.01   \n",
       "rumor3      0.97   \n",
       "rumor4      0.00   \n",
       "\n",
       "         topic12  \\\n",
       "rumor0      0.00   \n",
       "rumor1      0.00   \n",
       "rumor2!     0.01   \n",
       "rumor3      0.00   \n",
       "rumor4      0.00   \n",
       "\n",
       "         topic13  \\\n",
       "rumor0      0.00   \n",
       "rumor1      0.00   \n",
       "rumor2!     0.01   \n",
       "rumor3      0.00   \n",
       "rumor4      0.91   \n",
       "\n",
       "         topic14  \\\n",
       "rumor0      0.00   \n",
       "rumor1      0.00   \n",
       "rumor2!     0.01   \n",
       "rumor3      0.00   \n",
       "rumor4      0.00   \n",
       "\n",
       "         topic15  \n",
       "rumor0      0.00  \n",
       "rumor1      0.00  \n",
       "rumor2!     0.01  \n",
       "rumor3      0.00  \n",
       "rumor4      0.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia16_topic_vectors = ldia.transform(bow_docs)\n",
    "ldia16_topic_vectors = pd.DataFrame(ldia16_topic_vectors,\n",
    "                                    index=index, columns=columns)\n",
    "ldia16_topic_vectors.round(2).head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用LDiA主题向量训练LDA模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过采样前训练集中类别0的数量： 1479\n",
      "过采样前训练集中类别1的数量： 748\n",
      "过采样后训练集中类别0的数量： 1479\n",
      "过采样后训练集中类别1的数量： 1479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.596"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(ldia16_topic_vectors,df.rumor,test_size=0.2,random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "# 进行过采样\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"过采样前训练集中类别0的数量：\", sum(y_train==0))\n",
    "print(\"过采样前训练集中类别1的数量：\", sum(y_train==1))\n",
    "\n",
    "print(\"过采样后训练集中类别0的数量：\", sum(y_train_res==0))\n",
    "print(\"过采样后训练集中类别1的数量：\", sum(y_train_res==1))\n",
    "lda = LDA()\n",
    "lda = lda.fit(X_train_res, y_train_res)\n",
    "df['ldia16_rumor'] = lda.predict(ldia16_topic_vectors)\n",
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rumor507!',\n",
      "       'rumor2268',\n",
      "       'rumor2349',\n",
      "       'rumor1788',\n",
      "       'rumor949',\n",
      "       'rumor324',\n",
      "       'rumor1090',\n",
      "       'rumor1463!',\n",
      "       'rumor2227',\n",
      "       'rumor420',\n",
      "       ...\n",
      "       'rumor1309',\n",
      "       'rumor2408',\n",
      "       'rumor2226!',\n",
      "       'rumor461!',\n",
      "       'rumor927!',\n",
      "       'rumor157',\n",
      "       'rumor1657',\n",
      "       'rumor1724',\n",
      "       'rumor238!',\n",
      "       'rumor1813!'],\n",
      "      dtype='object', length=557)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      非rumor     0.7720    0.6046    0.6781       392\n",
      "       rumor     0.3800    0.5758    0.4578       165\n",
      "\n",
      "    accuracy                         0.5961       557\n",
      "   macro avg     0.5760    0.5902    0.5680       557\n",
      "weighted avg     0.6559    0.5961    0.6129       557\n",
      "\n",
      "[[237 155]\n",
      " [ 70  95]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "y_true = df.loc[y_test.index].rumor\n",
    "y_pred = df.loc[y_test.index].ldia16_rumor\n",
    "loss_total = 0\n",
    "acc = metrics.accuracy_score(y_true, y_pred)\n",
    "report = metrics.classification_report(y_true, y_pred, target_names=[\"非rumor\",\"rumor\"], digits=4)\n",
    "confusion = metrics.confusion_matrix(y_true, y_pred)\n",
    "print(report)\n",
    "print(confusion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对比TF-IDF向量的分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenyu/opt/anaconda3/envs/d2l/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import casual_tokenize\n",
    "tfidf = TfidfVectorizer(tokenizer=casual_tokenize,)\n",
    "tfidf_docs =tfidf.fit_transform(raw_documents=df.text).toarray()\n",
    "tfidf_docs = tfidf_docs - tfidf_docs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过采样前训练集中类别0的数量： 1479\n",
      "过采样前训练集中类别1的数量： 748\n",
      "过采样后训练集中类别0的数量： 1479\n",
      "过采样后训练集中类别1的数量： 1479\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(tfidf_docs,df.rumor,test_size=0.2,random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "# 进行过采样\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"过采样前训练集中类别0的数量：\", sum(y_train==0))\n",
    "print(\"过采样前训练集中类别1的数量：\", sum(y_train==1))\n",
    "\n",
    "print(\"过采样后训练集中类别0的数量：\", sum(y_train_res==0))\n",
    "print(\"过采样后训练集中类别1的数量：\", sum(y_train_res==1))\n",
    "lda = LDA()\n",
    "lda = lda.fit(X_train_res, y_train_res)\n",
    "df['tfidf_rumor'] = lda.predict(tfidf_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.786"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   non-rumor     0.8934    0.7908    0.8390       392\n",
      "       rumor     0.6095    0.7758    0.6827       165\n",
      "\n",
      "    accuracy                         0.7864       557\n",
      "   macro avg     0.7514    0.7833    0.7608       557\n",
      "weighted avg     0.8093    0.7864    0.7927       557\n",
      "\n",
      "[[310  82]\n",
      " [ 37 128]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "y_true = df.loc[y_test.index].rumor\n",
    "y_pred = df.loc[y_test.index].tfidf_rumor\n",
    "loss_total = 0\n",
    "acc = metrics.accuracy_score(y_true, y_pred)\n",
    "report = metrics.classification_report(y_true, y_pred, target_names=[\"non-rumor\",\"rumor\"], digits=4)\n",
    "confusion = metrics.confusion_matrix(y_true, y_pred)\n",
    "print(report)\n",
    "print(confusion)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDiA使用32个主题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 9200)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia32 = LDiA(n_components=300, learning_method='batch')\n",
    "ldia32 = ldia32.fit(bow_docs)  # <1>\n",
    "weights = pd.DataFrame(ldia32.components_, columns=terms,\n",
    "                       index = ['topic{}'.format(i) for i in range(ldia32.components_.shape[0])])\n",
    "ldia32.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic290</th>\n",
       "      <th>topic291</th>\n",
       "      <th>topic292</th>\n",
       "      <th>topic293</th>\n",
       "      <th>topic294</th>\n",
       "      <th>topic295</th>\n",
       "      <th>topic296</th>\n",
       "      <th>topic297</th>\n",
       "      <th>topic298</th>\n",
       "      <th>topic299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2!</th>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic0  \\\n",
       "rumor0   0.0001   \n",
       "rumor1   0.0001   \n",
       "rumor2!  0.0006   \n",
       "rumor3   0.0001   \n",
       "rumor4   0.0001   \n",
       "\n",
       "         topic1  \\\n",
       "rumor0   0.0001   \n",
       "rumor1   0.0001   \n",
       "rumor2!  0.0006   \n",
       "rumor3   0.0001   \n",
       "rumor4   0.0001   \n",
       "\n",
       "         topic2  \\\n",
       "rumor0   0.0001   \n",
       "rumor1   0.0001   \n",
       "rumor2!  0.0006   \n",
       "rumor3   0.0001   \n",
       "rumor4   0.0001   \n",
       "\n",
       "         topic3  \\\n",
       "rumor0   0.0001   \n",
       "rumor1   0.0001   \n",
       "rumor2!  0.0006   \n",
       "rumor3   0.0001   \n",
       "rumor4   0.0001   \n",
       "\n",
       "         topic4  \\\n",
       "rumor0   0.0001   \n",
       "rumor1   0.0001   \n",
       "rumor2!  0.0006   \n",
       "rumor3   0.0001   \n",
       "rumor4   0.0001   \n",
       "\n",
       "         topic5  \\\n",
       "rumor0   0.0001   \n",
       "rumor1   0.0001   \n",
       "rumor2!  0.0006   \n",
       "rumor3   0.0001   \n",
       "rumor4   0.0001   \n",
       "\n",
       "         topic6  \\\n",
       "rumor0   0.0001   \n",
       "rumor1   0.0001   \n",
       "rumor2!  0.0006   \n",
       "rumor3   0.0001   \n",
       "rumor4   0.0001   \n",
       "\n",
       "         topic7  \\\n",
       "rumor0   0.0001   \n",
       "rumor1   0.0001   \n",
       "rumor2!  0.0006   \n",
       "rumor3   0.0001   \n",
       "rumor4   0.0001   \n",
       "\n",
       "         topic8  \\\n",
       "rumor0   0.0001   \n",
       "rumor1   0.0001   \n",
       "rumor2!  0.0006   \n",
       "rumor3   0.0001   \n",
       "rumor4   0.0001   \n",
       "\n",
       "         topic9  \\\n",
       "rumor0   0.0001   \n",
       "rumor1   0.0001   \n",
       "rumor2!  0.0006   \n",
       "rumor3   0.0001   \n",
       "rumor4   0.0001   \n",
       "\n",
       "         ...  \\\n",
       "rumor0   ...   \n",
       "rumor1   ...   \n",
       "rumor2!  ...   \n",
       "rumor3   ...   \n",
       "rumor4   ...   \n",
       "\n",
       "         topic290  \\\n",
       "rumor0     0.0001   \n",
       "rumor1     0.0001   \n",
       "rumor2!    0.0006   \n",
       "rumor3     0.0001   \n",
       "rumor4     0.0001   \n",
       "\n",
       "         topic291  \\\n",
       "rumor0     0.0001   \n",
       "rumor1     0.0001   \n",
       "rumor2!    0.0006   \n",
       "rumor3     0.0001   \n",
       "rumor4     0.0001   \n",
       "\n",
       "         topic292  \\\n",
       "rumor0     0.0001   \n",
       "rumor1     0.0001   \n",
       "rumor2!    0.0006   \n",
       "rumor3     0.0001   \n",
       "rumor4     0.0001   \n",
       "\n",
       "         topic293  \\\n",
       "rumor0     0.0001   \n",
       "rumor1     0.0001   \n",
       "rumor2!    0.0006   \n",
       "rumor3     0.0001   \n",
       "rumor4     0.0001   \n",
       "\n",
       "         topic294  \\\n",
       "rumor0     0.0001   \n",
       "rumor1     0.0001   \n",
       "rumor2!    0.0006   \n",
       "rumor3     0.0001   \n",
       "rumor4     0.0001   \n",
       "\n",
       "         topic295  \\\n",
       "rumor0     0.0001   \n",
       "rumor1     0.0001   \n",
       "rumor2!    0.0006   \n",
       "rumor3     0.0001   \n",
       "rumor4     0.0001   \n",
       "\n",
       "         topic296  \\\n",
       "rumor0     0.0001   \n",
       "rumor1     0.0001   \n",
       "rumor2!    0.0006   \n",
       "rumor3     0.0001   \n",
       "rumor4     0.0001   \n",
       "\n",
       "         topic297  \\\n",
       "rumor0     0.0001   \n",
       "rumor1     0.0001   \n",
       "rumor2!    0.0006   \n",
       "rumor3     0.0001   \n",
       "rumor4     0.0001   \n",
       "\n",
       "         topic298  \\\n",
       "rumor0     0.0001   \n",
       "rumor1     0.0001   \n",
       "rumor2!    0.0006   \n",
       "rumor3     0.0001   \n",
       "rumor4     0.0001   \n",
       "\n",
       "         topic299  \n",
       "rumor0     0.0001  \n",
       "rumor1     0.0001  \n",
       "rumor2!    0.0006  \n",
       "rumor3     0.0001  \n",
       "rumor4     0.0001  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldia32_topic_vectors = ldia32.transform(bow_docs)\n",
    "columns32 = ['topic{}'.format(i) for i in range(ldia32.components_.shape[0])]\n",
    "ldia32_topic_vectors = pd.DataFrame(ldia32_topic_vectors,index=index, columns=columns32)\n",
    "ldia32_topic_vectors.round(4).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过采样前训练集中类别0的数量： 1479\n",
      "过采样前训练集中类别1的数量： 748\n",
      "过采样后训练集中类别0的数量： 1479\n",
      "过采样后训练集中类别1的数量： 1479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.882"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(ldia32_topic_vectors,df.rumor,test_size=0.2,random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "# 进行过采样\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "print(\"过采样前训练集中类别0的数量：\", sum(y_train==0))\n",
    "print(\"过采样前训练集中类别1的数量：\", sum(y_train==1))\n",
    "\n",
    "print(\"过采样后训练集中类别0的数量：\", sum(y_train_res==0))\n",
    "print(\"过采样后训练集中类别1的数量：\", sum(y_train_res==1))\n",
    "lda = LDA()\n",
    "lda = lda.fit(X_train_res, y_train_res)\n",
    "df['ldia32_rumor'] = lda.predict(ldia32_topic_vectors)\n",
    "round(float(lda.score(X_test, y_test)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   non-rumor     0.9075    0.9260    0.9167       392\n",
      "       rumor     0.8153    0.7758    0.7950       165\n",
      "\n",
      "    accuracy                         0.8815       557\n",
      "   macro avg     0.8614    0.8509    0.8558       557\n",
      "weighted avg     0.8802    0.8815    0.8806       557\n",
      "\n",
      "[[363  29]\n",
      " [ 37 128]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "y_true = df.loc[y_test.index].rumor\n",
    "y_pred = df.loc[y_test.index].ldia32_rumor\n",
    "loss_total = 0\n",
    "acc = metrics.accuracy_score(y_true, y_pred)\n",
    "report = metrics.classification_report(y_true, y_pred, target_names=[\"non-rumor\",\"rumor\"], digits=4)\n",
    "confusion = metrics.confusion_matrix(y_true, y_pred)\n",
    "print(report)\n",
    "print(confusion)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6d40a5097db4c11f3975da84c5456511726d6f156896da7e31bb0c17b283947"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
