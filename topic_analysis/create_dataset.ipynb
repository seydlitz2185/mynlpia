{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('smalldata_washed.csv')\n",
    "rumor = data['rumor'].to_list()\n",
    "reverse = data['reverse'].to_list()\n",
    "rumor_class = len(rumor)*[1]\n",
    "reverse_class = len(reverse)*[0]\n",
    "data = rumor + reverse\n",
    "data_class = rumor_class + reverse_class\n",
    "#后续添加数据要放在raw目录下，使用.xlsx格式将后续标注的数据加入data\n",
    "raw_data_list = os.listdir('raw')\n",
    "data_list = []\n",
    "good_name = re.compile(r'^(?!(\\~\\$)).*(.xlsx)')\n",
    "for i in raw_data_list:\n",
    "    if good_name.match(i):\n",
    "    #    data_list.append(i)\n",
    "        temp = pd.read_excel('raw/'+i)\n",
    "        temp.fillna('',inplace=True)\n",
    "        temp_rumor = [x.strip() for x in  temp['punc_rumor'].to_list()  if x.strip()!='']\n",
    "        temp_reverse = [x.strip() for x in  temp['punc_truth'].to_list()  if x.strip()!='']\n",
    "        temp_rumor_class = len(temp_rumor)*[1]\n",
    "        temp_reverse_class = len(temp_reverse)*[0]\n",
    "        temp_data = temp_rumor + temp_reverse\n",
    "        temp_data_class = temp_rumor_class + temp_reverse_class\n",
    "        for i in range( len(temp_data)):\n",
    "            temp_data[i]=re.sub(r'[\\,\\'\\ ]|(\\n)','',temp_data[i])\n",
    "    data = data + temp_data\n",
    "    data_class = data_class + temp_data_class\n",
    "with open('data.txt','w') as f:\n",
    "    for i in range(len(data)):\n",
    "        f.write(data[i]+'\\t'+str(data_class[i])+'\\n')\n",
    "        data_list =list( zip(data, data_class))\n",
    "random.shuffle(data_list)\n",
    "data, data_class = zip(*data_list)\n",
    "index = ['rumor{}{}'.format(i, '!' * j) for (i, j) in zip(range(len(data)), data_class)]\n",
    "df = pd .DataFrame(data=zip(data_class,data), columns=[\"rumor\",\"text\"], index=index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/f0/6j6j3w814n53skbt2s4d8p5m0000gn/T/jieba.cache\n",
      "Loading model cost 0.363 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "/Users/stevenyu/opt/anaconda3/envs/nlpiaenv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# jieba分词\n",
    "import jieba\n",
    "# 去除停用词\n",
    "with open ('hit_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    " \n",
    "seg_list = []\n",
    "for i in range(len(df)):\n",
    "    words = jieba.cut(df[\"text\"].iloc[i],cut_all=False)\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    seg_list.append( ' '.join(words))\n",
    " \n",
    "df['seg_text'] = seg_list\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "tfidf_model = TfidfVectorizer(tokenizer=casual_tokenize,ngram_range=(1,2))\n",
    "tfidf_docs = tfidf_model.fit_transform(raw_documents=df.seg_text).toarray()#这句话计算了tfidf\n",
    "tfidf_docs.shape\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_matrix = cosine_similarity(tfidf_docs)\n",
    "df['cos_matrix'] = cos_matrix.tolist()\n",
    "#snowNLP情感分析\n",
    "from snownlp import SnowNLP\n",
    "sentimentslist = []\n",
    "for i in (df['text']):\n",
    "    a1 = SnowNLP(i)\n",
    "    a2 = a1.sentiments\n",
    "    sentimentslist.append(a2)\n",
    "df['length'] = [len(x) for x in df['text']]\n",
    "df['sentiments'] = sentimentslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic90</th>\n",
       "      <th>topic91</th>\n",
       "      <th>topic92</th>\n",
       "      <th>topic93</th>\n",
       "      <th>topic94</th>\n",
       "      <th>topic95</th>\n",
       "      <th>topic96</th>\n",
       "      <th>topic97</th>\n",
       "      <th>topic98</th>\n",
       "      <th>topic99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0</th>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.042</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1</th>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.025</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2</th>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3!</th>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.082</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>0.065</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.038</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>0.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4</th>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>-0.067</td>\n",
       "      <td>0.101</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor5</th>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.134</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  \\\n",
       "rumor0    0.023  -0.042   0.010   0.002   0.007   0.000  -0.091   0.016   \n",
       "rumor1   -0.015  -0.012  -0.014   0.007   0.012   0.001   0.002   0.006   \n",
       "rumor2   -0.019  -0.013  -0.046   0.007   0.029   0.007  -0.006   0.025   \n",
       "rumor3!   0.027  -0.055   0.076   0.033   0.053   0.156  -0.125  -0.030   \n",
       "rumor4   -0.018  -0.025   0.056  -0.095  -0.044  -0.016  -0.001   0.141   \n",
       "rumor5    0.025  -0.032   0.044   0.134  -0.028  -0.051  -0.002   0.032   \n",
       "\n",
       "         topic8  topic9  ...  topic90  topic91  topic92  topic93  topic94  \\\n",
       "rumor0    0.041  -0.086  ...   -0.048   -0.002    0.004    0.043   -0.003   \n",
       "rumor1   -0.037   0.025  ...   -0.053    0.081    0.011   -0.051   -0.035   \n",
       "rumor2    0.002  -0.012  ...   -0.007    0.012   -0.001    0.013   -0.008   \n",
       "rumor3!  -0.031   0.082  ...   -0.032   -0.054    0.065   -0.021   -0.038   \n",
       "rumor4    0.037   0.005  ...   -0.012   -0.129   -0.035   -0.078   -0.067   \n",
       "rumor5    0.037   0.020  ...   -0.012   -0.040   -0.005   -0.019   -0.013   \n",
       "\n",
       "         topic95  topic96  topic97  topic98  topic99  \n",
       "rumor0    -0.007   -0.025    0.006    0.018   -0.002  \n",
       "rumor1    -0.012    0.023    0.001    0.056   -0.027  \n",
       "rumor2     0.021   -0.041   -0.022   -0.007    0.008  \n",
       "rumor3!    0.012    0.027    0.010   -0.041    0.122  \n",
       "rumor4     0.101   -0.072   -0.041   -0.104   -0.088  \n",
       "rumor5    -0.000   -0.037   -0.024   -0.027    0.000  \n",
       "\n",
       "[6 rows x 100 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "k=min(len(tfidf_model.vocabulary_),len(df))\n",
    "k=100\n",
    "pca = PCA(n_components=k)\n",
    "pca_docs = pca.fit_transform(tfidf_docs)\n",
    "base = sum(pca.singular_values_)\n",
    "nums = pca.singular_values_.tolist()\n",
    "pca = PCA(n_components=k)\n",
    "pca_docs = pca.fit_transform(tfidf_docs)\n",
    "pca_topic_vectors = pca.transform(tfidf_docs)\n",
    "columns = ['topic{}'.format(i) for i in range(pca_docs.shape[1])]\n",
    "pca_topic_vectors = pd.DataFrame(pca_topic_vectors, columns=columns, index=index)\n",
    "pca_topic_vectors.round(3).head(6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pca_topic_vectors'] = pca_topic_vectors.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenyu/opt/anaconda3/envs/nlpiaenv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic22</th>\n",
       "      <th>topic23</th>\n",
       "      <th>topic24</th>\n",
       "      <th>topic25</th>\n",
       "      <th>topic26</th>\n",
       "      <th>topic27</th>\n",
       "      <th>topic28</th>\n",
       "      <th>topic29</th>\n",
       "      <th>topic30</th>\n",
       "      <th>topic31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3!</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  \\\n",
       "rumor0     0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "rumor1     0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.01   \n",
       "rumor2     0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "rumor3!    0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.01   \n",
       "rumor4     0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "\n",
       "         topic8  topic9  ...  topic22  topic23  topic24  topic25  topic26  \\\n",
       "rumor0     0.00    0.00  ...     0.00     0.00     0.00     0.00     0.00   \n",
       "rumor1     0.01    0.01  ...     0.01     0.01     0.01     0.01     0.01   \n",
       "rumor2     0.00    0.00  ...     0.00     0.00     0.00     0.00     0.00   \n",
       "rumor3!    0.01    0.01  ...     0.01     0.01     0.01     0.01     0.01   \n",
       "rumor4     0.00    0.00  ...     0.00     0.00     0.00     0.00     0.94   \n",
       "\n",
       "         topic27  topic28  topic29  topic30  topic31  \n",
       "rumor0      0.00     0.00     0.00     0.00     0.00  \n",
       "rumor1      0.01     0.01     0.01     0.01     0.01  \n",
       "rumor2      0.00     0.00     0.00     0.00     0.00  \n",
       "rumor3!     0.01     0.01     0.01     0.01     0.01  \n",
       "rumor4      0.00     0.00     0.00     0.00     0.00  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import casual_tokenize\n",
    "np.random.seed(42)\n",
    "\n",
    "counter = CountVectorizer(tokenizer=casual_tokenize)\n",
    "bow_docs = pd.DataFrame(counter.fit_transform(raw_documents=df.text)\n",
    "                        .toarray(), index=index)\n",
    "column_nums, terms = zip(*sorted(zip(counter.vocabulary_.values(),\n",
    "                                     counter.vocabulary_.keys())))\n",
    "bow_docs.columns = terms\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDiA\n",
    "ldia = LDiA(n_components=32, learning_method='batch')\n",
    "ldia = ldia.fit(bow_docs)  # <1>\n",
    "ldia.components_.shape\n",
    "ldia32_topic_vectors = ldia.transform(bow_docs)\n",
    "columns32 = ['topic{}'.format(i) for i in range(ldia.components_.shape[0])]\n",
    "ldia32_topic_vectors = pd.DataFrame(ldia32_topic_vectors,index=index, columns=columns32)\n",
    "ldia32_topic_vectors.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ldia_topic_vectors'] = ldia32_topic_vectors.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../dataset/data.csv',encoding='utf-8')\n",
    "data = pd.read_csv('../dataset/data.csv',encoding='utf-8',index_col=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpiaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
