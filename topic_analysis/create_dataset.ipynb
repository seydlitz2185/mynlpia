{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('smalldata_washed.csv')\n",
    "rumor = data['rumor'].to_list()\n",
    "reverse = data['reverse'].to_list()\n",
    "rumor_class = len(rumor)*[1]\n",
    "reverse_class = len(reverse)*[0]\n",
    "data = rumor + reverse\n",
    "data_class = rumor_class + reverse_class\n",
    "#后续添加数据要放在raw目录下，使用.xlsx格式将后续标注的数据加入data\n",
    "raw_data_list = os.listdir('raw')\n",
    "data_list = []\n",
    "good_name = re.compile(r'^(?!(\\~\\$)).*(.xlsx)')\n",
    "for i in raw_data_list:\n",
    "    if good_name.match(i):\n",
    "    #    data_list.append(i)\n",
    "        temp = pd.read_excel('raw/'+i)\n",
    "        temp.fillna('',inplace=True)\n",
    "        temp_rumor = [x.strip() for x in  temp['punc_rumor'].to_list()  if x.strip()!='']\n",
    "        temp_reverse = [x.strip() for x in  temp['punc_truth'].to_list()  if x.strip()!='']\n",
    "        temp_rumor_class = len(temp_rumor)*[1]\n",
    "        temp_reverse_class = len(temp_reverse)*[0]\n",
    "        temp_data = temp_rumor + temp_reverse\n",
    "        temp_data_class = temp_rumor_class + temp_reverse_class\n",
    "        for i in range( len(temp_data)):\n",
    "            temp_data[i]=re.sub(r'[\\,\\'\\ ]|(\\n)','',temp_data[i])\n",
    "    data = data + temp_data\n",
    "    data_class = data_class + temp_data_class\n",
    "with open('data.txt','w') as f:\n",
    "    for i in range(len(data)):\n",
    "        f.write(data[i]+'\\t'+str(data_class[i])+'\\n')\n",
    "        data_list =list( zip(data, data_class))\n",
    "random.shuffle(data_list)\n",
    "data, data_class = zip(*data_list)\n",
    "index = ['rumor{}{}'.format(i, '!' * j) for (i, j) in zip(range(len(data)), data_class)]\n",
    "df = pd .DataFrame(data=zip(data_class,data), columns=[\"rumor\",\"text\"], index=index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/f0/6j6j3w814n53skbt2s4d8p5m0000gn/T/jieba.cache\n",
      "Loading model cost 0.504 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "/Users/stevenyu/opt/anaconda3/envs/nlpiaenv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# jieba分词\n",
    "import jieba\n",
    "# 去除停用词\n",
    "with open ('hit_stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    " \n",
    "seg_list = []\n",
    "for i in range(len(df)):\n",
    "    words = jieba.cut(df[\"text\"].iloc[i],cut_all=False)\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    seg_list.append( ' '.join(words))\n",
    " \n",
    "df['seg_text'] = seg_list\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize.casual import casual_tokenize\n",
    "tfidf_model = TfidfVectorizer(tokenizer=casual_tokenize,ngram_range=(1,2))\n",
    "tfidf_docs = tfidf_model.fit_transform(raw_documents=df.seg_text).toarray()#这句话计算了tfidf\n",
    "tfidf_docs.shape\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_matrix = cosine_similarity(tfidf_docs)\n",
    "df['cos_matrix'] = cos_matrix.tolist()\n",
    "#snowNLP情感分析\n",
    "from snownlp import SnowNLP\n",
    "sentimentslist = []\n",
    "for i in (df['text']):\n",
    "    a1 = SnowNLP(i)\n",
    "    a2 = a1.sentiments\n",
    "    sentimentslist.append(a2)\n",
    "df['length'] = [len(x) for x in df['text']]\n",
    "df['sentiments'] = sentimentslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic90</th>\n",
       "      <th>topic91</th>\n",
       "      <th>topic92</th>\n",
       "      <th>topic93</th>\n",
       "      <th>topic94</th>\n",
       "      <th>topic95</th>\n",
       "      <th>topic96</th>\n",
       "      <th>topic97</th>\n",
       "      <th>topic98</th>\n",
       "      <th>topic99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0</th>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.059</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.090</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1!</th>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2</th>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.079</td>\n",
       "      <td>0.015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3</th>\n",
       "      <td>0.050</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.091</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4</th>\n",
       "      <td>-0.047</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>0.075</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.059</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor5</th>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.049</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  \\\n",
       "rumor0    0.004  -0.061  -0.034   0.055   0.009   0.032   0.059  -0.045   \n",
       "rumor1!  -0.021   0.016  -0.015  -0.022   0.035  -0.022   0.006  -0.007   \n",
       "rumor2   -0.005  -0.017   0.035   0.133   0.047  -0.117  -0.018  -0.026   \n",
       "rumor3    0.050  -0.058   0.035   0.014   0.015   0.015  -0.051  -0.034   \n",
       "rumor4   -0.047   0.064   0.036  -0.055   0.075  -0.046   0.020  -0.005   \n",
       "rumor5   -0.010   0.010  -0.030   0.034   0.047  -0.084   0.056  -0.027   \n",
       "\n",
       "         topic8  topic9  ...  topic90  topic91  topic92  topic93  topic94  \\\n",
       "rumor0   -0.065  -0.061  ...   -0.006    0.038   -0.064   -0.118    0.036   \n",
       "rumor1!  -0.014   0.010  ...   -0.016   -0.019    0.003   -0.019   -0.036   \n",
       "rumor2   -0.079   0.015  ...    0.014    0.025   -0.039   -0.031   -0.007   \n",
       "rumor3    0.111   0.091  ...   -0.001   -0.013   -0.021   -0.010   -0.005   \n",
       "rumor4    0.033  -0.028  ...   -0.009    0.005   -0.001   -0.034   -0.059   \n",
       "rumor5    0.017  -0.028  ...   -0.000    0.029    0.049   -0.015    0.002   \n",
       "\n",
       "         topic95  topic96  topic97  topic98  topic99  \n",
       "rumor0     0.090   -0.010   -0.005    0.048   -0.053  \n",
       "rumor1!    0.026    0.007    0.019    0.031    0.034  \n",
       "rumor2    -0.061    0.011    0.005   -0.023    0.011  \n",
       "rumor3    -0.040    0.016    0.043    0.017    0.029  \n",
       "rumor4    -0.022    0.006    0.002    0.016    0.011  \n",
       "rumor5     0.032    0.017   -0.004   -0.010    0.037  \n",
       "\n",
       "[6 rows x 100 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "k=min(len(tfidf_model.vocabulary_),len(df))\n",
    "k=100\n",
    "pca = PCA(n_components=k)\n",
    "pca_docs = pca.fit_transform(tfidf_docs)\n",
    "base = sum(pca.singular_values_)\n",
    "nums = pca.singular_values_.tolist()\n",
    "pca = PCA(n_components=k)\n",
    "pca_docs = pca.fit_transform(tfidf_docs)\n",
    "pca_topic_vectors = pca.transform(tfidf_docs)\n",
    "columns = ['topic{}'.format(i) for i in range(pca_docs.shape[1])]\n",
    "pca_topic_vectors = pd.DataFrame(pca_topic_vectors, columns=columns, index=index)\n",
    "pca_topic_vectors.round(3).head(6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pca_topic_vectors'] = pca_topic_vectors.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stevenyu/opt/anaconda3/envs/nlpiaenv/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic0</th>\n",
       "      <th>topic1</th>\n",
       "      <th>topic2</th>\n",
       "      <th>topic3</th>\n",
       "      <th>topic4</th>\n",
       "      <th>topic5</th>\n",
       "      <th>topic6</th>\n",
       "      <th>topic7</th>\n",
       "      <th>topic8</th>\n",
       "      <th>topic9</th>\n",
       "      <th>...</th>\n",
       "      <th>topic22</th>\n",
       "      <th>topic23</th>\n",
       "      <th>topic24</th>\n",
       "      <th>topic25</th>\n",
       "      <th>topic26</th>\n",
       "      <th>topic27</th>\n",
       "      <th>topic28</th>\n",
       "      <th>topic29</th>\n",
       "      <th>topic30</th>\n",
       "      <th>topic31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rumor0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor1!</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rumor4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic0  topic1  topic2  topic3  topic4  topic5  topic6  topic7  \\\n",
       "rumor0     0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "rumor1!    0.02    0.02    0.02    0.02    0.02    0.02    0.02    0.02   \n",
       "rumor2     0.00    0.00    0.88    0.00    0.00    0.00    0.00    0.00   \n",
       "rumor3     0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "rumor4     0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "\n",
       "         topic8  topic9  ...  topic22  topic23  topic24  topic25  topic26  \\\n",
       "rumor0     0.93    0.00  ...     0.00     0.00     0.00     0.00     0.00   \n",
       "rumor1!    0.02    0.02  ...     0.02     0.02     0.02     0.02     0.02   \n",
       "rumor2     0.00    0.00  ...     0.00     0.00     0.00     0.00     0.00   \n",
       "rumor3     0.00    0.00  ...     0.00     0.00     0.00     0.00     0.00   \n",
       "rumor4     0.00    0.00  ...     0.00     0.00     0.00     0.00     0.00   \n",
       "\n",
       "         topic27  topic28  topic29  topic30  topic31  \n",
       "rumor0      0.00     0.00     0.00     0.00     0.00  \n",
       "rumor1!     0.02     0.02     0.02     0.52     0.02  \n",
       "rumor2      0.00     0.00     0.00     0.00     0.00  \n",
       "rumor3      0.00     0.00     0.00     0.00     0.00  \n",
       "rumor4      0.00     0.00     0.00     0.00     0.88  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import casual_tokenize\n",
    "np.random.seed(42)\n",
    "\n",
    "counter = CountVectorizer(tokenizer=casual_tokenize)\n",
    "bow_docs = pd.DataFrame(counter.fit_transform(raw_documents=df.text)\n",
    "                        .toarray(), index=index)\n",
    "column_nums, terms = zip(*sorted(zip(counter.vocabulary_.values(),\n",
    "                                     counter.vocabulary_.keys())))\n",
    "bow_docs.columns = terms\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDiA\n",
    "ldia = LDiA(n_components=32, learning_method='batch')\n",
    "ldia = ldia.fit(bow_docs)  # <1>\n",
    "ldia.components_.shape\n",
    "ldia32_topic_vectors = ldia.transform(bow_docs)\n",
    "columns32 = ['topic{}'.format(i) for i in range(ldia.components_.shape[0])]\n",
    "ldia32_topic_vectors = pd.DataFrame(ldia32_topic_vectors,index=index, columns=columns32)\n",
    "ldia32_topic_vectors.round(2).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ldia_topic_vectors'] = ldia32_topic_vectors.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../dataset/data.csv',encoding='utf-8')\n",
    "data = pd.read_csv('../dataset/data.csv',encoding='utf-8',index_col=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpiaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
